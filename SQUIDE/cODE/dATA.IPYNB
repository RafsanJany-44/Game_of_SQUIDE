{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1b685a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BSPM] Loaded 33 channels, length 100000 samples\n",
      "[BSPM] Dropped channel 33 (respiration). New shape: (32, 100000)\n",
      "[MCG group] C:\\Users\\RAZER\\Documents\\GitHub\\Game_of_SQUIDE\\SQUIDE\\dATASET\\dataset_2\\koch\\MOESM7\\MCG_CH_A1 -> 17 channels, 100000 samples\n",
      "[MCG group] C:\\Users\\RAZER\\Documents\\GitHub\\Game_of_SQUIDE\\SQUIDE\\dATASET\\dataset_2\\koch\\MOESM7\\MCG_CH_V1 -> 19 channels, 100000 samples\n",
      "[MCG group] C:\\Users\\RAZER\\Documents\\GitHub\\Game_of_SQUIDE\\SQUIDE\\dATASET\\dataset_2\\koch\\MOESM7\\MCG_CH_X1 -> 15 channels, 100000 samples\n",
      "[MCG group] C:\\Users\\RAZER\\Documents\\GitHub\\Game_of_SQUIDE\\SQUIDE\\dATASET\\dataset_2\\koch\\MOESM8\\MCG_CH_Z1 -> 17 channels, 100000 samples\n",
      "[MCG group] C:\\Users\\RAZER\\Documents\\GitHub\\Game_of_SQUIDE\\SQUIDE\\dATASET\\dataset_2\\koch\\MOESM8\\MCG_CH_Z2 -> 16 channels, 100000 samples\n",
      "[MCG group] C:\\Users\\RAZER\\Documents\\GitHub\\Game_of_SQUIDE\\SQUIDE\\dATASET\\dataset_2\\koch\\MOESM8\\MCG_CH_Z3 -> 16 channels, 100000 samples\n",
      "[MCG] Total concatenated shape: (100, 100000)\n",
      "[ALIGN] ECG shape: (32, 100000), MCG shape: (100, 100000)\n",
      "[R-PEAKS] Detected 130 peaks\n",
      "[RESULT] ECG beats: (127, 32, 2000), MCG beats: (127, 100, 2000)\n",
      "[SAVE] Saved Koch ECG–MCG pairs to koch_pairs.npz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "from scipy.signal import butter, filtfilt, find_peaks\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# 1. PATHS – EDIT THIS PART\n",
    "# ==========================\n",
    "\n",
    "KOCH_ROOT = r\"C:\\Users\\RAZER\\Documents\\GitHub\\Game_of_SQUIDE\\SQUIDE\\dATASET\\dataset_2\\koch\"\n",
    "\n",
    "MOESM6_DIR = os.path.join(KOCH_ROOT, \"MOESM6\")  # BSPM (ECG-like)\n",
    "MOESM7_DIR = os.path.join(KOCH_ROOT, \"MOESM7\")  # part 1 of MCG (A1, V1, X1)\n",
    "MOESM8_DIR = os.path.join(KOCH_ROOT, \"MOESM8\")  # part 2 of MCG (Z1, Z2, Z3)\n",
    "\n",
    "OUT_FILE = \"koch_pairs.npz\"\n",
    "FS = 1000  # sampling frequency: 1 ms interval\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# 2. LOADING FUNCTIONS\n",
    "# ==========================\n",
    "\n",
    "def load_bspm_ecg(moesm6_dir):\n",
    "    \"\"\"\n",
    "    Load BSPM (ECG-like) signals from MOESM6/BSPM_data/BSPM_CH_E*.txt\n",
    "\n",
    "    Returns:\n",
    "        ecg_bspm: (C_ecg, T)\n",
    "        file_list: list of txt file paths\n",
    "    \"\"\"\n",
    "    bspm_folder = os.path.join(moesm6_dir, \"BSPM_data\")\n",
    "    txt_files = sorted(glob(os.path.join(bspm_folder, \"BSPM_CH_E*.txt\")))\n",
    "    if not txt_files:\n",
    "        raise RuntimeError(f\"No BSPM_CH_E*.txt files found in {bspm_folder}\")\n",
    "\n",
    "    channels = []\n",
    "    for f in txt_files:\n",
    "        data = np.loadtxt(f, dtype=np.float32)\n",
    "        channels.append(data)\n",
    "\n",
    "    # Align lengths\n",
    "    min_len = min(len(ch) for ch in channels)\n",
    "    channels = [ch[:min_len] for ch in channels]\n",
    "    ecg_bspm = np.stack(channels, axis=0)  # (C, T)\n",
    "\n",
    "    print(f\"[BSPM] Loaded {ecg_bspm.shape[0]} channels, length {ecg_bspm.shape[1]} samples\")\n",
    "\n",
    "    # Scale as per paper: multiply by -1.0 * 10^(-6) to get mV\n",
    "    ecg_bspm = -1.0e-6 * ecg_bspm\n",
    "\n",
    "    # Channel 33 is respiration → E33 → index 32 (0-based)\n",
    "    if ecg_bspm.shape[0] >= 33:\n",
    "        idx = np.arange(ecg_bspm.shape[0])\n",
    "        idx = idx[idx != 32]\n",
    "        ecg_bspm = ecg_bspm[idx, :]\n",
    "        print(f\"[BSPM] Dropped channel 33 (respiration). New shape: {ecg_bspm.shape}\")\n",
    "\n",
    "    return ecg_bspm, txt_files\n",
    "\n",
    "\n",
    "def load_mcg_group(folder):\n",
    "    \"\"\"\n",
    "    Load all *.txt files from a given MCG_CH_* folder, e.g. MCG_CH_A1, MCG_CH_Z1.\n",
    "\n",
    "    Returns:\n",
    "        arr: (C_group, T)\n",
    "        files: list of txt paths\n",
    "    \"\"\"\n",
    "    txt_files = sorted(glob(os.path.join(folder, \"MCG_CH_*.txt\")))\n",
    "    if not txt_files:\n",
    "        raise RuntimeError(f\"No MCG_CH_*.txt in {folder}\")\n",
    "\n",
    "    channels = []\n",
    "    for f in txt_files:\n",
    "        data = np.loadtxt(f, dtype=np.float32)\n",
    "        channels.append(data)\n",
    "\n",
    "    min_len = min(len(ch) for ch in channels)\n",
    "    channels = [ch[:min_len] for ch in channels]\n",
    "    arr = np.stack(channels, axis=0)\n",
    "    print(f\"[MCG group] {folder} -> {arr.shape[0]} channels, {arr.shape[1]} samples\")\n",
    "    return arr, txt_files\n",
    "\n",
    "\n",
    "def load_full_mcg(moesm7_dir, moesm8_dir):\n",
    "    \"\"\"\n",
    "    Load all MCG channels from MOESM7 (MCG_CH_A1, V1, X1) and\n",
    "    MOESM8 (MCG_CH_Z1, Z2, Z3) and concatenate along channel axis.\n",
    "\n",
    "    Returns:\n",
    "        mcg_full: (C_mcg_total, T)\n",
    "        file_list: list of paths\n",
    "    \"\"\"\n",
    "    # Known subfolders from your dir listing:\n",
    "    mcg_groups_7 = [\"MCG_CH_A1\", \"MCG_CH_V1\", \"MCG_CH_X1\"]\n",
    "    mcg_groups_8 = [\"MCG_CH_Z1\", \"MCG_CH_Z2\", \"MCG_CH_Z3\"]\n",
    "\n",
    "    all_arrays = []\n",
    "    all_files = []\n",
    "\n",
    "    # Load A1, V1, X1\n",
    "    for grp in mcg_groups_7:\n",
    "        folder = os.path.join(moesm7_dir, grp)\n",
    "        if os.path.isdir(folder):\n",
    "            arr, files = load_mcg_group(folder)\n",
    "            all_arrays.append(arr)\n",
    "            all_files.extend(files)\n",
    "        else:\n",
    "            print(f\"[WARN] Missing folder: {folder}\")\n",
    "\n",
    "    # Load Z1, Z2, Z3\n",
    "    for grp in mcg_groups_8:\n",
    "        folder = os.path.join(moesm8_dir, grp)\n",
    "        if os.path.isdir(folder):\n",
    "            arr, files = load_mcg_group(folder)\n",
    "            all_arrays.append(arr)\n",
    "            all_files.extend(files)\n",
    "        else:\n",
    "            print(f\"[WARN] Missing folder: {folder}\")\n",
    "\n",
    "    if not all_arrays:\n",
    "        raise RuntimeError(\"No MCG groups found in MOESM7 or MOESM8\")\n",
    "\n",
    "    # Align lengths across all groups\n",
    "    min_len = min(a.shape[1] for a in all_arrays)\n",
    "    all_arrays = [a[:, :min_len] for a in all_arrays]\n",
    "\n",
    "    mcg_full = np.concatenate(all_arrays, axis=0)  # (C_total, T)\n",
    "    print(f\"[MCG] Total concatenated shape: {mcg_full.shape}\")\n",
    "    return mcg_full, all_files\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# 3. R-PEAK DETECTION\n",
    "# ==========================\n",
    "\n",
    "def bandpass_filter(signal, fs=1000, low=5.0, high=15.0, order=2):\n",
    "    nyq = 0.5 * fs\n",
    "    b, a = butter(order, [low / nyq, high / nyq], btype=\"band\")\n",
    "    return filtfilt(b, a, signal)\n",
    "\n",
    "\n",
    "def detect_r_peaks(signal, fs=1000, distance_ms=300, height_factor=0.4):\n",
    "    \"\"\"\n",
    "    Very basic R-peak detector for clean signals.\n",
    "    \"\"\"\n",
    "    filtered = bandpass_filter(signal, fs=fs, low=5.0, high=15.0, order=2)\n",
    "    distance = int(distance_ms * fs / 1000.0)\n",
    "    height = height_factor * np.max(filtered)\n",
    "    peaks, _ = find_peaks(filtered, distance=distance, height=height)\n",
    "    return peaks\n",
    "\n",
    "\n",
    "def normalize_beat(x):\n",
    "    \"\"\"\n",
    "    Channel-wise median/MAD normalization for a single beat window.\n",
    "    x: (C, T)\n",
    "    \"\"\"\n",
    "    m = np.median(x, axis=1, keepdims=True)\n",
    "    mad = np.median(np.abs(x - m), axis=1, keepdims=True) + 1e-6\n",
    "    return (x - m) / mad\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# 4. MAIN\n",
    "# ==========================\n",
    "\n",
    "def main():\n",
    "    # Load ECG (BSPM)\n",
    "    ecg_bspm, ecg_files = load_bspm_ecg(MOESM6_DIR)\n",
    "\n",
    "    # Load MCG (all groups from MOESM7 + MOESM8)\n",
    "    mcg, mcg_files = load_full_mcg(MOESM7_DIR, MOESM8_DIR)\n",
    "\n",
    "    # Align time length between ECG and MCG\n",
    "    T = min(ecg_bspm.shape[1], mcg.shape[1])\n",
    "    ecg_bspm = ecg_bspm[:, :T]\n",
    "    mcg = mcg[:, :T]\n",
    "    print(f\"[ALIGN] ECG shape: {ecg_bspm.shape}, MCG shape: {mcg.shape}\")\n",
    "\n",
    "    # Choose one ECG channel for R-peaks (channel 0 for now)\n",
    "    r_lead = ecg_bspm[0, :]\n",
    "    r_peaks = detect_r_peaks(r_lead, fs=FS, distance_ms=300, height_factor=0.4)\n",
    "    print(f\"[R-PEAKS] Detected {len(r_peaks)} peaks\")\n",
    "\n",
    "    # Extract 2-second windows around each R-peak\n",
    "    pre = int(0.5 * FS)   # 500 ms before R\n",
    "    post = int(1.5 * FS)  # 1500 ms after R\n",
    "    win_len = pre + post  # 2000 samples\n",
    "\n",
    "    ecg_beats = []\n",
    "    mcg_beats = []\n",
    "\n",
    "    for r in r_peaks:\n",
    "        start = r - pre\n",
    "        end = r + post\n",
    "        if start < 0 or end > T:\n",
    "            continue\n",
    "\n",
    "        ecg_win = ecg_bspm[:, start:end]  # (C_ecg, win_len)\n",
    "        mcg_win = mcg[:, start:end]       # (C_mcg, win_len)\n",
    "\n",
    "        if ecg_win.shape[1] != win_len or mcg_win.shape[1] != win_len:\n",
    "            continue\n",
    "\n",
    "        ecg_norm = normalize_beat(ecg_win).astype(np.float32)\n",
    "        mcg_norm = normalize_beat(mcg_win).astype(np.float32)\n",
    "\n",
    "        ecg_beats.append(ecg_norm)\n",
    "        mcg_beats.append(mcg_norm)\n",
    "\n",
    "    ecg_beats = np.stack(ecg_beats, axis=0)  # (N, C_ecg, 2000)\n",
    "    mcg_beats = np.stack(mcg_beats, axis=0)  # (N, C_mcg, 2000)\n",
    "\n",
    "    print(f\"[RESULT] ECG beats: {ecg_beats.shape}, MCG beats: {mcg_beats.shape}\")\n",
    "\n",
    "    # Save to NPZ\n",
    "    np.savez_compressed(\n",
    "        OUT_FILE,\n",
    "        ecg_beats=ecg_beats,\n",
    "        mcg_beats=mcg_beats,\n",
    "        fs=np.array([FS], dtype=np.int32),\n",
    "        ecg_channel_files=np.array(ecg_files, dtype=object),\n",
    "        mcg_channel_files=np.array(mcg_files, dtype=object),\n",
    "        description=np.array([\"Koch ECG (BSPM) + SQUID MCG, paired 2s beats\"], dtype=object),\n",
    "    )\n",
    "    print(f\"[SAVE] Saved Koch ECG–MCG pairs to {OUT_FILE}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "137ce4ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECG beats: (127, 32, 2000)\n",
      "MCG beats: (127, 100, 2000)\n",
      "fs: [1000]\n",
      "desc: ['Koch ECG (BSPM) + SQUID MCG, paired 2s beats']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.load(\"koch_pairs.npz\", allow_pickle=True)\n",
    "ecg_beats = data[\"ecg_beats\"]\n",
    "mcg_beats = data[\"mcg_beats\"]\n",
    "\n",
    "print(\"ECG beats:\", ecg_beats.shape)  # (127, 32, 2000)\n",
    "print(\"MCG beats:\", mcg_beats.shape)  # (127, 100, 2000)\n",
    "print(\"fs:\", data[\"fs\"])\n",
    "print(\"desc:\", data[\"description\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "689c5a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class KochPairedBeatsDataset(Dataset):\n",
    "    def __init__(self, npz_path=\"koch_pairs.npz\", augment=False):\n",
    "        \"\"\"\n",
    "        npz_path: path to the koch_pairs.npz file\n",
    "        augment: if True, apply very light noise / jitter augmentations\n",
    "        \"\"\"\n",
    "        data = np.load(npz_path, allow_pickle=True)\n",
    "        self.ecg_beats = data[\"ecg_beats\"]  # (N, C_ecg, T)\n",
    "        self.mcg_beats = data[\"mcg_beats\"]  # (N, C_mcg, T)\n",
    "        self.fs = int(data[\"fs\"][0])\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.ecg_beats.shape[0]\n",
    "\n",
    "    def _augment(self, x):\n",
    "        \"\"\"\n",
    "        x: numpy array (C, T)\n",
    "        very light augmentations: small Gaussian noise and tiny time shift\n",
    "        \"\"\"\n",
    "        # small noise\n",
    "        x = x + 0.01 * np.random.randn(*x.shape).astype(np.float32)\n",
    "\n",
    "        # tiny circular time shift up to ±20 samples\n",
    "        max_shift = 20\n",
    "        shift = np.random.randint(-max_shift, max_shift + 1)\n",
    "        if shift != 0:\n",
    "            x = np.roll(x, shift, axis=1)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ecg = self.ecg_beats[idx]  # (C_ecg, T)\n",
    "        mcg = self.mcg_beats[idx]  # (C_mcg, T)\n",
    "\n",
    "        if self.augment:\n",
    "            ecg = self._augment(ecg)\n",
    "            mcg = self._augment(mcg)\n",
    "\n",
    "        # convert to torch tensors\n",
    "        ecg = torch.from_numpy(ecg)  # float32, shape (C_ecg, T)\n",
    "        mcg = torch.from_numpy(mcg)  # float32, shape (C_mcg, T)\n",
    "\n",
    "        return ecg, mcg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57168083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num beats: 127\n",
      "ECG batch shape: torch.Size([8, 32, 2000])\n",
      "MCG batch shape: torch.Size([8, 100, 2000])\n"
     ]
    }
   ],
   "source": [
    "#from koch_dataset import KochPairedBeatsDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "ds = KochPairedBeatsDataset(\"koch_pairs.npz\", augment=False)\n",
    "print(\"Num beats:\", len(ds))\n",
    "\n",
    "loader = DataLoader(ds, batch_size=8, shuffle=True)\n",
    "ecg, mcg = next(iter(loader))\n",
    "print(\"ECG batch shape:\", ecg.shape)  # expect: torch.Size([8, 32, 2000])\n",
    "print(\"MCG batch shape:\", mcg.shape)  # expect: torch.Size([8, 100, 2000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c9b8eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 PTB records\n",
      "PTB beats shape: (362, 12, 2000)\n",
      "Saved PTB beats to ptb_beats.npz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import wfdb\n",
    "from scipy.signal import butter, filtfilt, find_peaks\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# 1. CONFIG – EDIT THIS PATH\n",
    "# ==========================\n",
    "\n",
    "PTB_ROOT = r\"C:\\Users\\RAZER\\Documents\\GitHub\\Game_of_SQUIDE\\SQUIDE\\dATASET\\physionet.org\\files\\ptbdb\\1.0.0\"   # TODO: change to your PTB folder\n",
    "OUT_FILE = \"ptb_beats.npz\"\n",
    "\n",
    "# Standard 12-lead names in PTB (lowercase in wfdb)\n",
    "STANDARD_LEADS = ['i', 'ii', 'iii', 'avr', 'avl', 'avf',\n",
    "                  'v1', 'v2', 'v3', 'v4', 'v5', 'v6']\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# 2. HELPERS\n",
    "# ==========================\n",
    "\n",
    "def list_ptb_records(ptb_root):\n",
    "    \"\"\"\n",
    "    Find all PTB records by searching for .hea files.\n",
    "    Returns a list of record paths without extension, e.g.\n",
    "    '...\\\\patient001\\\\s0010_re'\n",
    "    \"\"\"\n",
    "    rec_paths = []\n",
    "    for patient_dir in sorted(glob(os.path.join(ptb_root, 'patient*'))):\n",
    "        for hea in sorted(glob(os.path.join(patient_dir, '*.hea'))):\n",
    "            rec_paths.append(hea[:-4])  # drop '.hea'\n",
    "    return rec_paths\n",
    "\n",
    "\n",
    "def bandpass_filter(signal, fs=1000, low=5.0, high=15.0, order=2):\n",
    "    \"\"\"\n",
    "    Simple bandpass filter for QRS detection.\n",
    "    signal: 1D array\n",
    "    \"\"\"\n",
    "    nyq = 0.5 * fs\n",
    "    b, a = butter(order, [low / nyq, high / nyq], btype='band')\n",
    "    return filtfilt(b, a, signal)\n",
    "\n",
    "\n",
    "def detect_r_peaks(ecg_lead, fs=1000, distance_ms=300, height_factor=0.4):\n",
    "    \"\"\"\n",
    "    Very simple R-peak detector on a single lead.\n",
    "    ecg_lead: 1D numpy array\n",
    "    \"\"\"\n",
    "    filtered = bandpass_filter(ecg_lead, fs=fs, low=5.0, high=15.0, order=2)\n",
    "    distance = int(distance_ms * fs / 1000.0)   # minimal distance between peaks\n",
    "    height = height_factor * np.max(filtered)   # threshold\n",
    "    peaks, _ = find_peaks(filtered, distance=distance, height=height)\n",
    "    return peaks\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# 3. MAIN: BUILD PTB BEATS\n",
    "# ==========================\n",
    "\n",
    "def main():\n",
    "    rec_paths = list_ptb_records(PTB_ROOT)\n",
    "    print(f\"Found {len(rec_paths)} PTB records\")\n",
    "\n",
    "    all_beats = []\n",
    "    all_record_names = []\n",
    "    all_subject_ids = []\n",
    "    all_labels = []  # placeholder for diagnosis if you parse later\n",
    "\n",
    "    for rec_path in rec_paths:\n",
    "        rec_name = os.path.basename(rec_path)\n",
    "        patient_id = os.path.basename(os.path.dirname(rec_path))\n",
    "\n",
    "        try:\n",
    "            record = wfdb.rdrecord(rec_path)\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Failed to read {rec_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "        sig = record.p_signal       # shape (T, n_channels)\n",
    "        fs = int(record.fs)         # should be 1000\n",
    "        ch_names = [ch.lower() for ch in record.sig_name]\n",
    "\n",
    "        # Map 12 standard leads to indices\n",
    "        lead_indices = []\n",
    "        for ln in STANDARD_LEADS:\n",
    "            if ln in ch_names:\n",
    "                lead_indices.append(ch_names.index(ln))\n",
    "            else:\n",
    "                print(f\"[WARN] Lead {ln} not found in {rec_path}, skipping record.\")\n",
    "                lead_indices = []\n",
    "                break\n",
    "\n",
    "        if not lead_indices:\n",
    "            continue\n",
    "\n",
    "        # Extract matrix of shape (12, T)\n",
    "        ecg_12 = sig[:, lead_indices].T\n",
    "        T = ecg_12.shape[1]\n",
    "\n",
    "        # Use lead II for R-peak detection\n",
    "        if 'ii' not in ch_names:\n",
    "            print(f\"[WARN] No lead II in {rec_path}, skipping.\")\n",
    "            continue\n",
    "        lead2_index = ch_names.index('ii')\n",
    "        lead2 = sig[:, lead2_index]\n",
    "\n",
    "        # Detect R-peaks\n",
    "        r_peaks = detect_r_peaks(lead2, fs=fs, distance_ms=300, height_factor=0.4)\n",
    "\n",
    "        if len(r_peaks) < 5:\n",
    "            print(f\"[WARN] Few R-peaks ({len(r_peaks)}) in {rec_path}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        # 2-second window: [-0.5s, +1.5s] around each R → 2000 samples\n",
    "        pre = int(0.5 * fs)    # 500 samples\n",
    "        post = int(1.5 * fs)   # 1500 samples\n",
    "        win_len = pre + post   # 2000\n",
    "\n",
    "        for r in r_peaks:\n",
    "            start = r - pre\n",
    "            end = r + post\n",
    "            if start < 0 or end > T:\n",
    "                continue\n",
    "\n",
    "            beat = ecg_12[:, start:end]  # (12, 2000)\n",
    "            if beat.shape[1] != win_len:\n",
    "                continue\n",
    "\n",
    "            # Per-beat normalization (median + MAD)\n",
    "            m = np.median(beat, axis=1, keepdims=True)\n",
    "            mad = np.median(np.abs(beat - m), axis=1, keepdims=True) + 1e-6\n",
    "            beat_norm = (beat - m) / mad\n",
    "\n",
    "            all_beats.append(beat_norm.astype(np.float32))\n",
    "            all_record_names.append(rec_name)\n",
    "            all_subject_ids.append(patient_id)\n",
    "            all_labels.append(0)  # placeholder\n",
    "\n",
    "    if not all_beats:\n",
    "        print(\"No beats collected. Check PTB_ROOT and data structure.\")\n",
    "        return\n",
    "\n",
    "    all_beats = np.stack(all_beats, axis=0)  # (N, 12, 2000)\n",
    "    all_record_names = np.array(all_record_names)\n",
    "    all_subject_ids = np.array(all_subject_ids)\n",
    "    all_labels = np.array(all_labels)\n",
    "\n",
    "    print(\"PTB beats shape:\", all_beats.shape)\n",
    "\n",
    "    np.savez_compressed(\n",
    "        OUT_FILE,\n",
    "        beats=all_beats,\n",
    "        record_names=all_record_names,\n",
    "        subject_ids=all_subject_ids,\n",
    "        labels=all_labels,\n",
    "        fs=np.array([1000], dtype=np.int32),\n",
    "        description=np.array([\"PTB 12-lead beats, 2s windows around R-peaks\"], dtype=object),\n",
    "    )\n",
    "    print(f\"Saved PTB beats to {OUT_FILE}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b0cbc00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beats: (362, 12, 2000)\n",
      "fs: [1000]\n",
      "desc: ['PTB 12-lead beats, 2s windows around R-peaks']\n",
      "examples from records: ['s0010_re' 's0010_re' 's0010_re' 's0010_re' 's0010_re']\n",
      "subjects: ['patient001' 'patient001' 'patient001' 'patient001' 'patient001']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "ptb = np.load(\"ptb_beats.npz\", allow_pickle=True)\n",
    "print(\"beats:\", ptb[\"beats\"].shape)          # (N, 12, 2000)\n",
    "print(\"fs:\", ptb[\"fs\"])\n",
    "print(\"desc:\", ptb[\"description\"])\n",
    "print(\"examples from records:\", ptb[\"record_names\"][:5])\n",
    "print(\"subjects:\", ptb[\"subject_ids\"][:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8870c32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class PTBBeatsDataset(Dataset):\n",
    "    def __init__(self, npz_path=\"ptb_beats.npz\", augment=True):\n",
    "        data = np.load(npz_path, allow_pickle=True)\n",
    "        self.beats = data[\"beats\"]        # (N, 12, 2000)\n",
    "        self.fs = int(data[\"fs\"][0])\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.beats.shape[0]\n",
    "\n",
    "    def _augment(self, x):\n",
    "        # x: (12, T)\n",
    "        x = x + 0.01 * np.random.randn(*x.shape).astype(np.float32)  # noise\n",
    "        max_shift = 20\n",
    "        shift = np.random.randint(-max_shift, max_shift + 1)\n",
    "        if shift != 0:\n",
    "            x = np.roll(x, shift, axis=1)\n",
    "        return x\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        beat = self.beats[idx]\n",
    "        if self.augment:\n",
    "            beat = self._augment(beat)\n",
    "        return torch.from_numpy(beat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16fde24c-5183-48cd-ae96-5d9390fec57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 12, 2000])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "ds_ptb = PTBBeatsDataset(\"ptb_beats.npz\", augment=True)\n",
    "loader_ptb = DataLoader(ds_ptb, batch_size=32, shuffle=True)\n",
    "\n",
    "batch = next(iter(loader_ptb))\n",
    "print(batch.shape)  # torch.Size([32, 12, 2000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90c9c54b-c23d-406b-9699-069f32fe323c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class PTBBeatsDataset(Dataset):\n",
    "    def __init__(self, npz_path=\"ptb_beats.npz\", augment=True):\n",
    "        data = np.load(npz_path, allow_pickle=True)\n",
    "        self.beats = data[\"beats\"]        # (N, 12, 2000)\n",
    "        self.fs = int(data[\"fs\"][0])\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.beats.shape[0]\n",
    "\n",
    "    def _augment(self, x):\n",
    "        \"\"\"\n",
    "        x: numpy array (12, T)\n",
    "        Simple SimCLR-style augmentations:\n",
    "        - small Gaussian noise\n",
    "        - small circular time shift\n",
    "        \"\"\"\n",
    "        x = x + 0.01 * np.random.randn(*x.shape).astype(np.float32)\n",
    "        max_shift = 20\n",
    "        shift = np.random.randint(-max_shift, max_shift + 1)\n",
    "        if shift != 0:\n",
    "            x = np.roll(x, shift, axis=1)\n",
    "        return x\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.beats[idx]  # (12, 2000)\n",
    "\n",
    "        # For SimCLR we need TWO views of the same beat\n",
    "        x1 = self._augment(x.copy())\n",
    "        x2 = self._augment(x.copy())\n",
    "\n",
    "        x1 = torch.from_numpy(x1)  # (12, 2000)\n",
    "        x2 = torch.from_numpy(x2)\n",
    "\n",
    "        return x1, x2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b11665c-2a7e-4548-881e-e8e415a9072b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num PTB beats: 362\n",
      "torch.Size([32, 12, 2000]) torch.Size([32, 12, 2000])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "#from ptb_dataset import PTBBeatsDataset\n",
    "\n",
    "ds = PTBBeatsDataset(\"ptb_beats.npz\", augment=True)\n",
    "print(\"Num PTB beats:\", len(ds))\n",
    "\n",
    "loader = DataLoader(ds, batch_size=32, shuffle=True)\n",
    "v1, v2 = next(iter(loader))\n",
    "print(v1.shape, v2.shape)  # expect: [32, 12, 2000] [32, 12, 2000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55a6875a-7950-4d33-830c-531c61d343b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class ECGEncoderCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple 1D CNN encoder for ECG beats.\n",
    "    Input: (B, C=12, T=2000)\n",
    "    Output: (B, feat_dim)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels=12, feat_dim=256):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.bn1   = nn.BatchNorm1d(64)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(64, 128, kernel_size=5, stride=2, padding=2)\n",
    "        self.bn2   = nn.BatchNorm1d(128)\n",
    "\n",
    "        self.conv3 = nn.Conv1d(128, 256, kernel_size=5, stride=2, padding=2)\n",
    "        self.bn3   = nn.BatchNorm1d(256)\n",
    "\n",
    "        self.conv4 = nn.Conv1d(256, 256, kernel_size=3, stride=2, padding=1)\n",
    "        self.bn4   = nn.BatchNorm1d(256)\n",
    "\n",
    "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(256, feat_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (B, C, T)\n",
    "        \"\"\"\n",
    "        x = F.relu(self.bn1(self.conv1(x)))  # (B, 64, T/2)\n",
    "        x = F.relu(self.bn2(self.conv2(x)))  # (B, 128, T/4)\n",
    "        x = F.relu(self.bn3(self.conv3(x)))  # (B, 256, T/8)\n",
    "        x = F.relu(self.bn4(self.conv4(x)))  # (B, 256, T/16)\n",
    "        x = self.global_pool(x)              # (B, 256, 1)\n",
    "        x = x.squeeze(-1)                    # (B, 256)\n",
    "        x = self.fc(x)                       # (B, feat_dim)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ProjectionHead(nn.Module):\n",
    "    \"\"\"\n",
    "    2-layer MLP projection head for SimCLR.\n",
    "    Input: (B, feat_dim)\n",
    "    Output: (B, proj_dim)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim=256, proj_dim=128):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_dim, in_dim)\n",
    "        self.fc2 = nn.Linear(in_dim, proj_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        # L2 normalize\n",
    "        x = F.normalize(x, p=2, dim=-1)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c3cff922-4bff-4089-a52c-54f428c84378",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class ECGEncoderCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple 1D CNN encoder for ECG beats.\n",
    "    Input: (B, C=12, T=2000)\n",
    "    Output: (B, feat_dim)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels=12, feat_dim=256):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.bn1   = nn.BatchNorm1d(64)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(64, 128, kernel_size=5, stride=2, padding=2)\n",
    "        self.bn2   = nn.BatchNorm1d(128)\n",
    "\n",
    "        self.conv3 = nn.Conv1d(128, 256, kernel_size=5, stride=2, padding=2)\n",
    "        self.bn3   = nn.BatchNorm1d(256)\n",
    "\n",
    "        self.conv4 = nn.Conv1d(256, 256, kernel_size=3, stride=2, padding=1)\n",
    "        self.bn4   = nn.BatchNorm1d(256)\n",
    "\n",
    "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(256, feat_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (B, C, T)\n",
    "        \"\"\"\n",
    "        x = F.relu(self.bn1(self.conv1(x)))  # (B, 64, T/2)\n",
    "        x = F.relu(self.bn2(self.conv2(x)))  # (B, 128, T/4)\n",
    "        x = F.relu(self.bn3(self.conv3(x)))  # (B, 256, T/8)\n",
    "        x = F.relu(self.bn4(self.conv4(x)))  # (B, 256, T/16)\n",
    "        x = self.global_pool(x)              # (B, 256, 1)\n",
    "        x = x.squeeze(-1)                    # (B, 256)\n",
    "        x = self.fc(x)                       # (B, feat_dim)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ProjectionHead(nn.Module):\n",
    "    \"\"\"\n",
    "    2-layer MLP projection head for SimCLR.\n",
    "    Input: (B, feat_dim)\n",
    "    Output: (B, proj_dim)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim=256, proj_dim=128):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_dim, in_dim)\n",
    "        self.fc2 = nn.Linear(in_dim, proj_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        # L2 normalize\n",
    "        x = F.normalize(x, p=2, dim=-1)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2721e344-8cbe-4c50-b1e4-5f4224551397",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def simclr_nt_xent_loss(z1, z2, temperature=0.1):\n",
    "    \"\"\"\n",
    "    z1, z2: (B, D) normalized embeddings from two views of the same batch.\n",
    "    Returns scalar loss.\n",
    "    \"\"\"\n",
    "    assert z1.shape == z2.shape\n",
    "    batch_size = z1.shape[0]\n",
    "\n",
    "    z = torch.cat([z1, z2], dim=0)  # (2B, D)\n",
    "    sim = F.cosine_similarity(z.unsqueeze(1), z.unsqueeze(0), dim=-1)  # (2B, 2B)\n",
    "\n",
    "    # Mask to remove self-similarity\n",
    "    self_mask = torch.eye(2 * batch_size, dtype=torch.bool, device=z.device)\n",
    "    sim = sim / temperature\n",
    "\n",
    "    # For each anchor i in 0..2B-1, define positives and negatives\n",
    "    # Positives: (i, i+B) or (i, i-B) depending on which half\n",
    "    labels = torch.arange(2 * batch_size, device=z.device)\n",
    "    labels = (labels + batch_size) % (2 * batch_size)  # positive index for each anchor\n",
    "\n",
    "    # For cross-entropy, we need logits (2B, 2B-1) and labels\n",
    "    sim = sim.masked_fill(self_mask, -1e9)\n",
    "\n",
    "    loss = F.cross_entropy(sim, labels)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a3817bcf-75dd-4663-a89d-5e6aa4c4e308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Epoch 001/50 - SimCLR loss: 2.6459\n",
      "Epoch 002/50 - SimCLR loss: 1.1079\n",
      "Epoch 003/50 - SimCLR loss: 0.6489\n",
      "Epoch 004/50 - SimCLR loss: 0.4174\n",
      "Epoch 005/50 - SimCLR loss: 0.3391\n",
      "Epoch 006/50 - SimCLR loss: 0.2616\n",
      "Epoch 007/50 - SimCLR loss: 0.2033\n",
      "Epoch 008/50 - SimCLR loss: 0.1476\n",
      "Epoch 009/50 - SimCLR loss: 0.1429\n",
      "Epoch 010/50 - SimCLR loss: 0.1264\n",
      "Epoch 011/50 - SimCLR loss: 0.1099\n",
      "Epoch 012/50 - SimCLR loss: 0.1040\n",
      "Epoch 013/50 - SimCLR loss: 0.0866\n",
      "Epoch 014/50 - SimCLR loss: 0.0873\n",
      "Epoch 015/50 - SimCLR loss: 0.0799\n",
      "Epoch 016/50 - SimCLR loss: 0.0804\n",
      "Epoch 017/50 - SimCLR loss: 0.0584\n",
      "Epoch 018/50 - SimCLR loss: 0.0531\n",
      "Epoch 019/50 - SimCLR loss: 0.0608\n",
      "Epoch 020/50 - SimCLR loss: 0.0563\n",
      "Epoch 021/50 - SimCLR loss: 0.0483\n",
      "Epoch 022/50 - SimCLR loss: 0.0445\n",
      "Epoch 023/50 - SimCLR loss: 0.0454\n",
      "Epoch 024/50 - SimCLR loss: 0.0452\n",
      "Epoch 025/50 - SimCLR loss: 0.0440\n",
      "Epoch 026/50 - SimCLR loss: 0.0354\n",
      "Epoch 027/50 - SimCLR loss: 0.0380\n",
      "Epoch 028/50 - SimCLR loss: 0.0328\n",
      "Epoch 029/50 - SimCLR loss: 0.0369\n",
      "Epoch 030/50 - SimCLR loss: 0.0322\n",
      "Epoch 031/50 - SimCLR loss: 0.0319\n",
      "Epoch 032/50 - SimCLR loss: 0.0292\n",
      "Epoch 033/50 - SimCLR loss: 0.0268\n",
      "Epoch 034/50 - SimCLR loss: 0.0266\n",
      "Epoch 035/50 - SimCLR loss: 0.0275\n",
      "Epoch 036/50 - SimCLR loss: 0.0229\n",
      "Epoch 037/50 - SimCLR loss: 0.0212\n",
      "Epoch 038/50 - SimCLR loss: 0.0228\n",
      "Epoch 039/50 - SimCLR loss: 0.0212\n",
      "Epoch 040/50 - SimCLR loss: 0.0206\n",
      "Epoch 041/50 - SimCLR loss: 0.0196\n",
      "Epoch 042/50 - SimCLR loss: 0.0211\n",
      "Epoch 043/50 - SimCLR loss: 0.0212\n",
      "Epoch 044/50 - SimCLR loss: 0.0198\n",
      "Epoch 045/50 - SimCLR loss: 0.0207\n",
      "Epoch 046/50 - SimCLR loss: 0.0193\n",
      "Epoch 047/50 - SimCLR loss: 0.0192\n",
      "Epoch 048/50 - SimCLR loss: 0.0188\n",
      "Epoch 049/50 - SimCLR loss: 0.0184\n",
      "Epoch 050/50 - SimCLR loss: 0.0174\n",
      "Saved pretrained ECG encoder to ecg_encoder_ptb_simclr.pth\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "#from ptb_dataset import PTBBeatsDataset\n",
    "#from models import ECGEncoderCNN, ProjectionHead, simclr_nt_xent_loss\n",
    "\n",
    "\n",
    "def train_ptb_simclr(\n",
    "    npz_path=\"ptb_beats.npz\",\n",
    "    batch_size=64,\n",
    "    lr=1e-3,\n",
    "    epochs=50,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    # Dataset & DataLoader\n",
    "    dataset = PTBBeatsDataset(npz_path=npz_path, augment=True)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "    # Model\n",
    "    encoder = ECGEncoderCNN(in_channels=12, feat_dim=256)\n",
    "    projector = ProjectionHead(in_dim=256, proj_dim=128)\n",
    "\n",
    "    encoder.to(device)\n",
    "    projector.to(device)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        list(encoder.parameters()) + list(projector.parameters()),\n",
    "        lr=lr,\n",
    "        weight_decay=1e-4,\n",
    "    )\n",
    "\n",
    "    encoder.train()\n",
    "    projector.train()\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        running_loss = 0.0\n",
    "        for step, (x1, x2) in enumerate(loader):\n",
    "            x1 = x1.to(device)  # (B, 12, 2000)\n",
    "            x2 = x2.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward both views through encoder + projector\n",
    "            h1 = encoder(x1)          # (B, 256)\n",
    "            h2 = encoder(x2)          # (B, 256)\n",
    "            z1 = projector(h1)        # (B, 128)\n",
    "            z2 = projector(h2)        # (B, 128)\n",
    "\n",
    "            loss = simclr_nt_xent_loss(z1, z2, temperature=0.1)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_loss = running_loss / (step + 1)\n",
    "        print(f\"Epoch {epoch:03d}/{epochs} - SimCLR loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # Save encoder weights to reuse for Koch cross-modal training\n",
    "    torch.save(encoder.state_dict(), \"ecg_encoder_ptb_simclr.pth\")\n",
    "    print(\"Saved pretrained ECG encoder to ecg_encoder_ptb_simclr.pth\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(\"Using device:\", device)\n",
    "    train_ptb_simclr(\n",
    "        npz_path=\"ptb_beats.npz\",\n",
    "        batch_size=64,\n",
    "        lr=1e-3,\n",
    "        epochs=50,\n",
    "        device=device,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "120ee169-69c9-4e6a-b9f7-d7957b899d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Conv1DEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Generic 1D CNN encoder for time series.\n",
    "    Used for ECG (C=12 or 32) and MCG (C=100).\n",
    "    Input: (B, C, T)\n",
    "    Output: (B, feat_dim)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, feat_dim=256):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.bn1   = nn.BatchNorm1d(64)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(64, 128, kernel_size=5, stride=2, padding=2)\n",
    "        self.bn2   = nn.BatchNorm1d(128)\n",
    "\n",
    "        self.conv3 = nn.Conv1d(128, 256, kernel_size=5, stride=2, padding=2)\n",
    "        self.bn3   = nn.BatchNorm1d(256)\n",
    "\n",
    "        self.conv4 = nn.Conv1d(256, 256, kernel_size=3, stride=2, padding=1)\n",
    "        self.bn4   = nn.BatchNorm1d(256)\n",
    "\n",
    "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(256, feat_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, C, T)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))  # (B, 64, T/2)\n",
    "        x = F.relu(self.bn2(self.conv2(x)))  # (B, 128, T/4)\n",
    "        x = F.relu(self.bn3(self.conv3(x)))  # (B, 256, T/8)\n",
    "        x = F.relu(self.bn4(self.conv4(x)))  # (B, 256, T/16)\n",
    "        x = self.global_pool(x)              # (B, 256, 1)\n",
    "        x = x.squeeze(-1)                    # (B, 256)\n",
    "        x = self.fc(x)                       # (B, feat_dim)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ProjectionHead(nn.Module):\n",
    "    \"\"\"\n",
    "    2-layer MLP projection head.\n",
    "    Input: (B, feat_dim)\n",
    "    Output: (B, proj_dim) normalized\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim=256, proj_dim=128):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_dim, in_dim)\n",
    "        self.fc2 = nn.Linear(in_dim, proj_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = F.normalize(x, p=2, dim=-1)\n",
    "        return x\n",
    "\n",
    "\n",
    "def cross_modal_info_nce(z_e, z_m, temperature=0.1):\n",
    "    \"\"\"\n",
    "    Cross-modal InfoNCE loss between ECG (z_e) and MCG (z_m).\n",
    "    z_e: (B, D) ECG embeddings (L2-normalized)\n",
    "    z_m: (B, D) MCG embeddings (L2-normalized)\n",
    "\n",
    "    We compute similarity matrix S = z_e @ z_m^T / T\n",
    "    and use symmetric loss: ECG→MCG and MCG→ECG.\n",
    "    \"\"\"\n",
    "    assert z_e.shape == z_m.shape\n",
    "    B, D = z_e.shape\n",
    "\n",
    "    # cosine similarity (since both are normalized, dot = cos)\n",
    "    logits = z_e @ z_m.T / temperature  # (B, B)\n",
    "\n",
    "    targets = torch.arange(B, device=z_e.device)\n",
    "\n",
    "    # ECG→MCG\n",
    "    loss_e2m = F.cross_entropy(logits, targets)\n",
    "\n",
    "    # MCG→ECG (transpose)\n",
    "    loss_m2e = F.cross_entropy(logits.T, targets)\n",
    "\n",
    "    loss = 0.5 * (loss_e2m + loss_m2e)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ffdab42c-de2a-454a-96fe-c96a4bc87699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Loading PTB-pretrained ECG encoder from ecg_encoder_ptb_simclr.pth\n",
      "Loaded PTB weights into Koch ECG encoder (with conv1 channel adaptation).\n",
      "Epoch 001/100 - Cross-modal loss: 2.1133\n",
      "Epoch 002/100 - Cross-modal loss: 2.0697\n",
      "Epoch 003/100 - Cross-modal loss: 2.0526\n",
      "Epoch 004/100 - Cross-modal loss: 2.0576\n",
      "Epoch 005/100 - Cross-modal loss: 2.0723\n",
      "Epoch 006/100 - Cross-modal loss: 2.0715\n",
      "Epoch 007/100 - Cross-modal loss: 2.0712\n",
      "Epoch 008/100 - Cross-modal loss: 2.0711\n",
      "Epoch 009/100 - Cross-modal loss: 2.0711\n",
      "Epoch 010/100 - Cross-modal loss: 2.0710\n",
      "Epoch 011/100 - Cross-modal loss: 2.0709\n",
      "Epoch 012/100 - Cross-modal loss: 2.0707\n",
      "Epoch 013/100 - Cross-modal loss: 2.0701\n",
      "Epoch 014/100 - Cross-modal loss: 2.0655\n",
      "Epoch 015/100 - Cross-modal loss: 2.0041\n",
      "Epoch 016/100 - Cross-modal loss: 1.9330\n",
      "Epoch 017/100 - Cross-modal loss: 1.9330\n",
      "Epoch 018/100 - Cross-modal loss: 1.7987\n",
      "Epoch 019/100 - Cross-modal loss: 1.6050\n",
      "Epoch 020/100 - Cross-modal loss: 1.5144\n",
      "Epoch 021/100 - Cross-modal loss: 1.6635\n",
      "Epoch 022/100 - Cross-modal loss: 1.4026\n",
      "Epoch 023/100 - Cross-modal loss: 1.4560\n",
      "Epoch 024/100 - Cross-modal loss: 1.4105\n",
      "Epoch 025/100 - Cross-modal loss: 1.4605\n",
      "Epoch 026/100 - Cross-modal loss: 1.3503\n",
      "Epoch 027/100 - Cross-modal loss: 1.3526\n",
      "Epoch 028/100 - Cross-modal loss: 1.3035\n",
      "Epoch 029/100 - Cross-modal loss: 1.1879\n",
      "Epoch 030/100 - Cross-modal loss: 1.2474\n",
      "Epoch 031/100 - Cross-modal loss: 1.1987\n",
      "Epoch 032/100 - Cross-modal loss: 1.3503\n",
      "Epoch 033/100 - Cross-modal loss: 1.4421\n",
      "Epoch 034/100 - Cross-modal loss: 1.3098\n",
      "Epoch 035/100 - Cross-modal loss: 1.2047\n",
      "Epoch 036/100 - Cross-modal loss: 1.2123\n",
      "Epoch 037/100 - Cross-modal loss: 1.0639\n",
      "Epoch 038/100 - Cross-modal loss: 1.1388\n",
      "Epoch 039/100 - Cross-modal loss: 1.2666\n",
      "Epoch 040/100 - Cross-modal loss: 1.1591\n",
      "Epoch 041/100 - Cross-modal loss: 1.2788\n",
      "Epoch 042/100 - Cross-modal loss: 1.2282\n",
      "Epoch 043/100 - Cross-modal loss: 1.0638\n",
      "Epoch 044/100 - Cross-modal loss: 1.0069\n",
      "Epoch 045/100 - Cross-modal loss: 0.9824\n",
      "Epoch 046/100 - Cross-modal loss: 1.0287\n",
      "Epoch 047/100 - Cross-modal loss: 0.9674\n",
      "Epoch 048/100 - Cross-modal loss: 1.0779\n",
      "Epoch 049/100 - Cross-modal loss: 1.1692\n",
      "Epoch 050/100 - Cross-modal loss: 0.8506\n",
      "Epoch 051/100 - Cross-modal loss: 1.2187\n",
      "Epoch 052/100 - Cross-modal loss: 1.0293\n",
      "Epoch 053/100 - Cross-modal loss: 0.8795\n",
      "Epoch 054/100 - Cross-modal loss: 0.9402\n",
      "Epoch 055/100 - Cross-modal loss: 0.9011\n",
      "Epoch 056/100 - Cross-modal loss: 0.9655\n",
      "Epoch 057/100 - Cross-modal loss: 0.9615\n",
      "Epoch 058/100 - Cross-modal loss: 0.8497\n",
      "Epoch 059/100 - Cross-modal loss: 0.9983\n",
      "Epoch 060/100 - Cross-modal loss: 1.0681\n",
      "Epoch 061/100 - Cross-modal loss: 0.9104\n",
      "Epoch 062/100 - Cross-modal loss: 1.0044\n",
      "Epoch 063/100 - Cross-modal loss: 1.0834\n",
      "Epoch 064/100 - Cross-modal loss: 0.8918\n",
      "Epoch 065/100 - Cross-modal loss: 0.7212\n",
      "Epoch 066/100 - Cross-modal loss: 0.7650\n",
      "Epoch 067/100 - Cross-modal loss: 0.7907\n",
      "Epoch 068/100 - Cross-modal loss: 0.8160\n",
      "Epoch 069/100 - Cross-modal loss: 0.9467\n",
      "Epoch 070/100 - Cross-modal loss: 1.0403\n",
      "Epoch 071/100 - Cross-modal loss: 0.9710\n",
      "Epoch 072/100 - Cross-modal loss: 0.7838\n",
      "Epoch 073/100 - Cross-modal loss: 0.6987\n",
      "Epoch 074/100 - Cross-modal loss: 0.8842\n",
      "Epoch 075/100 - Cross-modal loss: 0.7939\n",
      "Epoch 076/100 - Cross-modal loss: 0.7655\n",
      "Epoch 077/100 - Cross-modal loss: 0.7903\n",
      "Epoch 078/100 - Cross-modal loss: 0.8097\n",
      "Epoch 079/100 - Cross-modal loss: 0.7039\n",
      "Epoch 080/100 - Cross-modal loss: 0.8051\n",
      "Epoch 081/100 - Cross-modal loss: 0.8329\n",
      "Epoch 082/100 - Cross-modal loss: 0.8229\n",
      "Epoch 083/100 - Cross-modal loss: 0.9178\n",
      "Epoch 084/100 - Cross-modal loss: 0.7958\n",
      "Epoch 085/100 - Cross-modal loss: 0.6998\n",
      "Epoch 086/100 - Cross-modal loss: 0.8240\n",
      "Epoch 087/100 - Cross-modal loss: 0.7529\n",
      "Epoch 088/100 - Cross-modal loss: 0.8570\n",
      "Epoch 089/100 - Cross-modal loss: 0.6876\n",
      "Epoch 090/100 - Cross-modal loss: 0.6541\n",
      "Epoch 091/100 - Cross-modal loss: 0.7560\n",
      "Epoch 092/100 - Cross-modal loss: 0.8402\n",
      "Epoch 093/100 - Cross-modal loss: 0.6861\n",
      "Epoch 094/100 - Cross-modal loss: 0.6763\n",
      "Epoch 095/100 - Cross-modal loss: 0.6977\n",
      "Epoch 096/100 - Cross-modal loss: 0.7122\n",
      "Epoch 097/100 - Cross-modal loss: 0.6096\n",
      "Epoch 098/100 - Cross-modal loss: 0.7230\n",
      "Epoch 099/100 - Cross-modal loss: 0.6870\n",
      "Epoch 100/100 - Cross-modal loss: 0.6743\n",
      "Saved ECG + MCG encoders and projection heads for Koch dataset\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "#from koch_dataset import KochPairedBeatsDataset\n",
    "#from models import Conv1DEncoder, ProjectionHead, cross_modal_info_nce\n",
    "\n",
    "\n",
    "def train_koch_crossmodal(\n",
    "    npz_path=\"koch_pairs.npz\",\n",
    "    batch_size=8,\n",
    "    lr=1e-3,\n",
    "    epochs=100,\n",
    "    device=\"cpu\",\n",
    "    pretrained_ecg_path=None\n",
    "):\n",
    "    # 1) Dataset & DataLoader\n",
    "    dataset = KochPairedBeatsDataset(npz_path=npz_path, augment=True)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "    # 2) Encoders: ECG (32 channels) and MCG (100 channels)\n",
    "    ecg_encoder = Conv1DEncoder(in_channels=32, feat_dim=256)\n",
    "    mcg_encoder = Conv1DEncoder(in_channels=100, feat_dim=256)\n",
    "\n",
    "    # Optionally load pretrained ECG weights (from PTB SimCLR)\n",
    "    if pretrained_ecg_path is not None:\n",
    "        print(f\"Loading PTB-pretrained ECG encoder from {pretrained_ecg_path}\")\n",
    "        load_ptb_weights_into_koch_encoder(ecg_encoder, pretrained_ecg_path,\n",
    "                                           in_channels_ptb=12, in_channels_koch=32)\n",
    "\n",
    "    # Projection heads\n",
    "    ecg_proj = ProjectionHead(in_dim=256, proj_dim=128)\n",
    "    mcg_proj = ProjectionHead(in_dim=256, proj_dim=128)\n",
    "\n",
    "    ecg_encoder.to(device)\n",
    "    mcg_encoder.to(device)\n",
    "    ecg_proj.to(device)\n",
    "    mcg_proj.to(device)\n",
    "\n",
    "    # 3) Optimizer\n",
    "    # You can use smaller LR for pretrained ECG encoder if you want\n",
    "    params = list(ecg_encoder.parameters()) + list(mcg_encoder.parameters()) \\\n",
    "             + list(ecg_proj.parameters()) + list(mcg_proj.parameters())\n",
    "\n",
    "    optimizer = torch.optim.AdamW(params, lr=lr, weight_decay=1e-4)\n",
    "\n",
    "    # 4) Training loop\n",
    "    ecg_encoder.train()\n",
    "    mcg_encoder.train()\n",
    "    ecg_proj.train()\n",
    "    mcg_proj.train()\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for step, (ecg, mcg) in enumerate(loader):\n",
    "            ecg = ecg.to(device)  # (B, 32, 2000)\n",
    "            mcg = mcg.to(device)  # (B, 100, 2000)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Encode\n",
    "            h_e = ecg_encoder(ecg)    # (B, 256)\n",
    "            h_m = mcg_encoder(mcg)    # (B, 256)\n",
    "\n",
    "            # Project\n",
    "            z_e = ecg_proj(h_e)       # (B, 128)\n",
    "            z_m = mcg_proj(h_m)       # (B, 128)\n",
    "\n",
    "            # Cross-modal InfoNCE\n",
    "            loss = cross_modal_info_nce(z_e, z_m, temperature=0.1)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_loss = running_loss / (step + 1)\n",
    "        print(f\"Epoch {epoch:03d}/{epochs} - Cross-modal loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # 5) Save trained models\n",
    "    torch.save(ecg_encoder.state_dict(), \"ecg_encoder_koch.pth\")\n",
    "    torch.save(mcg_encoder.state_dict(), \"mcg_encoder_koch.pth\")\n",
    "    torch.save(ecg_proj.state_dict(), \"ecg_proj_koch.pth\")\n",
    "    torch.save(mcg_proj.state_dict(), \"mcg_proj_koch.pth\")\n",
    "    print(\"Saved ECG + MCG encoders and projection heads for Koch dataset\")\n",
    "\n",
    "import torch\n",
    "\n",
    "def load_ptb_weights_into_koch_encoder(ecg_encoder, ckpt_path, in_channels_ptb=12, in_channels_koch=32):\n",
    "    \"\"\"\n",
    "    Load PTB-pretrained weights (12 channels) into a Koch ECG encoder (32 channels).\n",
    "    All layers except conv1 are loaded directly.\n",
    "    conv1.weight is adapted by tiling the 12-channel kernels to 32 channels.\n",
    "    \"\"\"\n",
    "    ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "    enc_state = ecg_encoder.state_dict()\n",
    "\n",
    "    new_state = {}\n",
    "\n",
    "    for k, v in enc_state.items():\n",
    "        if k == \"conv1.weight\":\n",
    "            if \"conv1.weight\" in ckpt:\n",
    "                w_ptb = ckpt[\"conv1.weight\"]  # (64, 12, 7)\n",
    "                # tile channels: repeat along in_channel dim until >=32, then cut\n",
    "                repeat_factor = (in_channels_koch + in_channels_ptb - 1) // in_channels_ptb\n",
    "                w_tiled = w_ptb.repeat(1, repeat_factor, 1)  # (64, 12*repeat, 7)\n",
    "                w_tiled = w_tiled[:, :in_channels_koch, :]   # (64, 32, 7)\n",
    "                new_state[k] = w_tiled\n",
    "            else:\n",
    "                new_state[k] = v  # fallback: keep random init\n",
    "        elif k == \"conv1.bias\":\n",
    "            if \"conv1.bias\" in ckpt:\n",
    "                new_state[k] = ckpt[\"conv1.bias\"]\n",
    "            else:\n",
    "                new_state[k] = v\n",
    "        else:\n",
    "            # for all other layers, load if shape matches, else keep default\n",
    "            if k in ckpt and ckpt[k].shape == v.shape:\n",
    "                new_state[k] = ckpt[k]\n",
    "            else:\n",
    "                new_state[k] = v\n",
    "\n",
    "    ecg_encoder.load_state_dict(new_state)\n",
    "    print(\"Loaded PTB weights into Koch ECG encoder (with conv1 channel adaptation).\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(\"Using device:\", device)\n",
    "\n",
    "    # If you have PTB-pretrained encoder:\n",
    "    pretrained_path = \"ecg_encoder_ptb_simclr.pth\"  # or None if you didn’t train it yet\n",
    "\n",
    "    train_koch_crossmodal(\n",
    "    npz_path=\"koch_pairs.npz\",\n",
    "    batch_size=8,\n",
    "    lr=1e-3,\n",
    "    epochs=100,\n",
    "    device=device,\n",
    "    pretrained_ecg_path=\"ecg_encoder_ptb_simclr.pth\",\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400c8118-a6b5-43b5-ad1d-fe12ca809204",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d350b05e-08f6-4e38-9e15-4f1e3178989c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad02d977-778e-4ca0-b6ed-37032c898dae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a45e588-3c28-4883-848d-9dda608e96e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d504a5-2fa7-400c-89cd-b000822b5bdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b4143b-2204-406a-aeda-6e4afb37784c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40429fb8-ec16-4b84-8962-5788b5c0af35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e06209-374e-4e6f-9ec6-aabbb3ae00d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b9d305-59f3-4a45-906e-3bbd6d6e9a23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fa165b-ce13-4747-93ff-f9e0c878b38b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3630e0e5-6e28-4861-89d4-be50dd3bf702",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19c3dc7-6c8a-4c1a-9473-e76cd999a75f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4528d6b8-482b-4dac-8b91-b0e3d2bd11ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2141268-866a-4b7b-bcea-53b66bd0a5ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209b8c6c-fe08-4eb0-b62d-bb92b9355a79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0abc944-315f-4fde-9cfb-e3c52ee2ee6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f66d9b9-7c29-4e54-b191-65ec101a7848",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14db5e90-4b2a-44c0-a1c2-579e89f88ab3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e8bbc6-edfe-4565-832b-59a113ed13ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee26d5f0",
   "metadata": {},
   "source": [
    "# 1. PTB ECG – Prepare Beat-Level Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a879187d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import wfdb\n",
    "from scipy.signal import find_peaks, butter, filtfilt\n",
    "\n",
    "\n",
    "def list_ptb_records(ptb_root):\n",
    "    \"\"\"\n",
    "    ptb_root: path to PTB root folder, e.g. 'data/ptbdb'\n",
    "    Returns list of full record paths without extension, e.g. '.../patient001/s0010_re'\n",
    "    \"\"\"\n",
    "    rec_paths = []\n",
    "    for patient_dir in sorted(glob(os.path.join(ptb_root, 'patient*'))):\n",
    "        for rec in sorted(glob(os.path.join(patient_dir, '*.hea'))):\n",
    "            rec_paths.append(rec[:-4])  # strip '.hea'\n",
    "    return rec_paths\n",
    "\n",
    "\n",
    "def bandpass_filter(signal, fs=1000, low=5.0, high=15.0, order=2):\n",
    "    \"\"\"\n",
    "    Simple bandpass filter for QRS detection.\n",
    "    signal: 1D numpy array\n",
    "    fs: sampling frequency\n",
    "    \"\"\"\n",
    "    nyq = 0.5 * fs\n",
    "    b, a = butter(order, [low / nyq, high / nyq], btype='band')\n",
    "    return filtfilt(b, a, signal)\n",
    "    \n",
    "\n",
    "def detect_r_peaks(ecg_lead, fs=1000, distance_ms=300, height_factor=0.5):\n",
    "    \"\"\"\n",
    "    Very basic R-peak detector on a single lead.\n",
    "    ecg_lead: 1D numpy array\n",
    "    distance_ms: minimum distance between peaks\n",
    "    height_factor: relative threshold on peak height\n",
    "    Returns indices of R-peaks.\n",
    "    \"\"\"\n",
    "    filtered = bandpass_filter(ecg_lead, fs=fs, low=5.0, high=15.0)\n",
    "    distance = int(distance_ms * fs / 1000.0)\n",
    "    # rough threshold: height_factor * max\n",
    "    height = height_factor * np.max(filtered)\n",
    "    peaks, _ = find_peaks(filtered, distance=distance, height=height)\n",
    "    return peaks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adc47b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import wfdb\n",
    "from collections import defaultdict\n",
    "\n",
    "PTB_ROOT = \"data/ptbdb\"    # TODO: change to your path\n",
    "OUT_FILE = \"ptb_beats.npz\" # output\n",
    "\n",
    "# standard 12 leads in PTB header\n",
    "STANDARD_LEADS = ['i', 'ii', 'iii', 'avr', 'avl', 'avf',\n",
    "                  'v1', 'v2', 'v3', 'v4', 'v5', 'v6']\n",
    "\n",
    "all_beats = []\n",
    "all_record_names = []\n",
    "all_subject_ids = []\n",
    "all_labels = []  # you can later fill with MI/non-MI, etc.\n",
    "\n",
    "rec_paths = list_ptb_records(PTB_ROOT)\n",
    "print(f\"Found {len(rec_paths)} records\")\n",
    "\n",
    "for rec_path in rec_paths:\n",
    "    try:\n",
    "        record = wfdb.rdrecord(rec_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to read {rec_path}: {e}\")\n",
    "        continue\n",
    "\n",
    "    sig = record.p_signal  # shape (T, n_channels)\n",
    "    fs = int(record.fs)    # should be 1000\n",
    "    ch_names = [ch.lower() for ch in record.sig_name]\n",
    "\n",
    "    # map lead names to indices\n",
    "    lead_indices = []\n",
    "    for ln in STANDARD_LEADS:\n",
    "        if ln in ch_names:\n",
    "            lead_indices.append(ch_names.index(ln))\n",
    "        else:\n",
    "            print(f\"Lead {ln} not found in {rec_path}, skipping record.\")\n",
    "            lead_indices = []\n",
    "            break\n",
    "\n",
    "    if not lead_indices:\n",
    "        continue\n",
    "\n",
    "    ecg_12 = sig[:, lead_indices].T  # shape (12, T)\n",
    "    T = ecg_12.shape[1]\n",
    "\n",
    "    # use lead II for R-peak detection\n",
    "    lead2_index = ch_names.index('ii')\n",
    "    lead2 = sig[:, lead2_index]\n",
    "    r_peaks = detect_r_peaks(lead2, fs=fs, distance_ms=300, height_factor=0.4)\n",
    "\n",
    "    if len(r_peaks) < 5:\n",
    "        print(f\"Few R-peaks in {rec_path}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    # 2-second window: [-500ms, +1500ms] → 2000 samples\n",
    "    pre = int(0.5 * fs)\n",
    "    post = int(1.5 * fs)\n",
    "    win_len = pre + post\n",
    "\n",
    "    for r in r_peaks:\n",
    "        start = r - pre\n",
    "        end = r + post\n",
    "        if start < 0 or end > T:\n",
    "            continue\n",
    "        beat = ecg_12[:, start:end]  # (12, 2000)\n",
    "        if beat.shape[1] != win_len:\n",
    "            continue\n",
    "\n",
    "        # simple per-beat normalization (median + MAD)\n",
    "        m = np.median(beat, axis=1, keepdims=True)\n",
    "        mad = np.median(np.abs(beat - m), axis=1, keepdims=True) + 1e-6\n",
    "        beat_norm = (beat - m) / mad\n",
    "\n",
    "        all_beats.append(beat_norm.astype(np.float32))\n",
    "        all_record_names.append(os.path.basename(rec_path))\n",
    "        # subject id is patient folder name\n",
    "        all_subject_ids.append(os.path.basename(os.path.dirname(rec_path)))\n",
    "        all_labels.append(0)  # placeholder; you can parse .hea for diagnosis later\n",
    "\n",
    "all_beats = np.stack(all_beats, axis=0)  # (N, 12, 2000)\n",
    "all_record_names = np.array(all_record_names)\n",
    "all_subject_ids = np.array(all_subject_ids)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "print(\"PTB beats shape:\", all_beats.shape)\n",
    "\n",
    "np.savez_compressed(\n",
    "    OUT_FILE,\n",
    "    beats=all_beats,\n",
    "    record_names=all_record_names,\n",
    "    subject_ids=all_subject_ids,\n",
    "    labels=all_labels,\n",
    "    fs=np.array([1000], dtype=np.int32),\n",
    "    description=np.array([\"PTB 12-lead beats, 2s windows around R-peaks\"], dtype=object)\n",
    ")\n",
    "print(f\"Saved PTB beats to {OUT_FILE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f026130",
   "metadata": {},
   "source": [
    "# 2. Koch ECG–MCG – Prepare Paired Beat Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f49cbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
