{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d207600",
   "metadata": {},
   "source": [
    "# KOCH PAIRED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb940958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num beats: 127\n",
      "ECG batch shape: torch.Size([8, 32, 2000])\n",
      "MCG batch shape: torch.Size([8, 100, 2000])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "from scipy.signal import butter, filtfilt, find_peaks\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class KochPairedBeatsDataset(Dataset):\n",
    "    def __init__(self, npz_path=\"koch_pairs.npz\", augment=False):\n",
    "        \"\"\"\n",
    "        npz_path: path to the koch_pairs.npz file\n",
    "        augment: if True, apply very light noise / jitter augmentations\n",
    "        \"\"\"\n",
    "        data = np.load(npz_path, allow_pickle=True)\n",
    "        self.ecg_beats = data[\"ecg_beats\"]  # (N, C_ecg, T)\n",
    "        self.mcg_beats = data[\"mcg_beats\"]  # (N, C_mcg, T)\n",
    "        self.fs = int(data[\"fs\"][0])\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.ecg_beats.shape[0]\n",
    "\n",
    "    def _augment(self, x):\n",
    "        \"\"\"\n",
    "        x: numpy array (C, T)\n",
    "        very light augmentations: small Gaussian noise and tiny time shift\n",
    "        \"\"\"\n",
    "        # small noise\n",
    "        x = x + 0.01 * np.random.randn(*x.shape).astype(np.float32)\n",
    "\n",
    "        # tiny circular time shift up to ±20 samples\n",
    "        max_shift = 20\n",
    "        shift = np.random.randint(-max_shift, max_shift + 1)\n",
    "        if shift != 0:\n",
    "            x = np.roll(x, shift, axis=1)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ecg = self.ecg_beats[idx]  # (C_ecg, T)\n",
    "        mcg = self.mcg_beats[idx]  # (C_mcg, T)\n",
    "\n",
    "        if self.augment:\n",
    "            ecg = self._augment(ecg)\n",
    "            mcg = self._augment(mcg)\n",
    "\n",
    "        # convert to torch tensors\n",
    "        ecg = torch.from_numpy(ecg)  # float32, shape (C_ecg, T)\n",
    "        mcg = torch.from_numpy(mcg)  # float32, shape (C_mcg, T)\n",
    "\n",
    "        return ecg, mcg\n",
    "\n",
    "\n",
    "#from koch_dataset import KochPairedBeatsDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "ds = KochPairedBeatsDataset(\"koch_pairs.npz\", augment=False)\n",
    "print(\"Num beats:\", len(ds))\n",
    "\n",
    "loader = DataLoader(ds, batch_size=8, shuffle=True)\n",
    "ecg, mcg = next(iter(loader))\n",
    "print(\"ECG batch shape:\", ecg.shape)  # expect: torch.Size([8, 32, 2000])\n",
    "print(\"MCG batch shape:\", mcg.shape)  # expect: torch.Size([8, 100, 2000])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec958b0",
   "metadata": {},
   "source": [
    "# PTB Beats Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a1a8383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 12, 2000])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class PTBBeatsDataset(Dataset):\n",
    "    def __init__(self, npz_path=\"ptb_beats.npz\", augment=True):\n",
    "        data = np.load(npz_path, allow_pickle=True)\n",
    "        self.beats = data[\"beats\"]        # (N, 12, 2000)\n",
    "        self.fs = int(data[\"fs\"][0])\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.beats.shape[0]\n",
    "\n",
    "    def _augment(self, x):\n",
    "        # x: (12, T)\n",
    "        x = x + 0.01 * np.random.randn(*x.shape).astype(np.float32)  # noise\n",
    "        max_shift = 20\n",
    "        shift = np.random.randint(-max_shift, max_shift + 1)\n",
    "        if shift != 0:\n",
    "            x = np.roll(x, shift, axis=1)\n",
    "        return x\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        beat = self.beats[idx]\n",
    "        if self.augment:\n",
    "            beat = self._augment(beat)\n",
    "        return torch.from_numpy(beat)\n",
    "\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "ds_ptb = PTBBeatsDataset(\"ptb_beats.npz\", augment=True)\n",
    "loader_ptb = DataLoader(ds_ptb, batch_size=32, shuffle=True)\n",
    "\n",
    "batch = next(iter(loader_ptb))\n",
    "print(batch.shape)  # torch.Size([32, 12, 2000])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c119102e",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34cf37b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "class DepthwiseSeparableConv1d(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, kernel_size, stride=1, padding=0):\n",
    "        super().__init__()\n",
    "        self.depthwise = nn.Conv1d(in_ch, in_ch, kernel_size=kernel_size,\n",
    "                                   stride=stride, padding=padding, groups=in_ch)\n",
    "        self.pointwise = nn.Conv1d(in_ch, out_ch, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.depthwise(x)\n",
    "        x = self.pointwise(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MultiScaleBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-scale depthwise-separable residual block.\n",
    "    Input: (B, C, T) -> Output: (B, C, T)\n",
    "    \"\"\"\n",
    "    def __init__(self, channels, kernels=(5, 9, 17)):\n",
    "        super().__init__()\n",
    "        self.branches = nn.ModuleList()\n",
    "        for k in kernels:\n",
    "            pad = k // 2\n",
    "            self.branches.append(\n",
    "                DepthwiseSeparableConv1d(channels, channels, kernel_size=k, padding=pad)\n",
    "            )\n",
    "        self.bn = nn.BatchNorm1d(channels)\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, C, T)\n",
    "        outs = []\n",
    "        for conv in self.branches:\n",
    "            outs.append(conv(x))\n",
    "        out = sum(outs) / len(outs)  # average branches\n",
    "        out = self.bn(out)\n",
    "        out = self.act(out)\n",
    "        return x + out  # residual\n",
    "\n",
    "\n",
    "class SMEEBackbone(nn.Module):\n",
    "    \"\"\"\n",
    "    Shared Multi-Scale Efficient Encoder backbone.\n",
    "    Input: (B, C_bottleneck, T) -> Output: (B, feat_dim)\n",
    "    \"\"\"\n",
    "    def __init__(self, bottleneck_channels=32, n_blocks=3, feat_dim=256):\n",
    "        super().__init__()\n",
    "        blocks = []\n",
    "        for _ in range(n_blocks):\n",
    "            blocks.append(MultiScaleBlock(bottleneck_channels, kernels=(5, 9, 17)))\n",
    "        self.blocks = nn.Sequential(*blocks)\n",
    "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(bottleneck_channels, feat_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, C_bottleneck, T)\n",
    "        x = self.blocks(x)                 # (B, C_bottleneck, T)\n",
    "        x = self.global_pool(x).squeeze(-1)  # (B, C_bottleneck)\n",
    "        x = self.fc(x)                     # (B, feat_dim)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ECGEncoderSMEE(nn.Module):\n",
    "    \"\"\"\n",
    "    ECG encoder using SMEE backbone.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels=32, bottleneck_channels=32, feat_dim=256):\n",
    "        super().__init__()\n",
    "        self.input_proj = nn.Conv1d(in_channels, bottleneck_channels, kernel_size=1)\n",
    "        self.backbone = SMEEBackbone(bottleneck_channels=bottleneck_channels,\n",
    "                                     n_blocks=3, feat_dim=feat_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_proj(x)\n",
    "        x = self.backbone(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MCGEncoderSMEE(nn.Module):\n",
    "    \"\"\"\n",
    "    MCG encoder using SMEE backbone. Can share backbone weights with ECG encoder if desired.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int = 100,\n",
    "        bottleneck_channels: int = 32,\n",
    "        feat_dim: int = 256,\n",
    "        shared_backbone: Optional[SMEEBackbone] = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.input_proj = nn.Conv1d(in_channels, bottleneck_channels, kernel_size=1)\n",
    "        if shared_backbone is None:\n",
    "            self.backbone = SMEEBackbone(\n",
    "                bottleneck_channels=bottleneck_channels,\n",
    "                n_blocks=3,\n",
    "                feat_dim=feat_dim,\n",
    "            )\n",
    "        else:\n",
    "            self.backbone = shared_backbone  # weight sharing\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_proj(x)\n",
    "        x = self.backbone(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Conv1DEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Generic 1D CNN encoder for time series.\n",
    "    Used for ECG (C=12 or 32) and MCG (C=100).\n",
    "    Input: (B, C, T)\n",
    "    Output: (B, feat_dim)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, feat_dim=256):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.bn1   = nn.BatchNorm1d(64)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(64, 128, kernel_size=5, stride=2, padding=2)\n",
    "        self.bn2   = nn.BatchNorm1d(128)\n",
    "\n",
    "        self.conv3 = nn.Conv1d(128, 256, kernel_size=5, stride=2, padding=2)\n",
    "        self.bn3   = nn.BatchNorm1d(256)\n",
    "\n",
    "        self.conv4 = nn.Conv1d(256, 256, kernel_size=3, stride=2, padding=1)\n",
    "        self.bn4   = nn.BatchNorm1d(256)\n",
    "\n",
    "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(256, feat_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, C, T)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))  # (B, 64, T/2)\n",
    "        x = F.relu(self.bn2(self.conv2(x)))  # (B, 128, T/4)\n",
    "        x = F.relu(self.bn3(self.conv3(x)))  # (B, 256, T/8)\n",
    "        x = F.relu(self.bn4(self.conv4(x)))  # (B, 256, T/16)\n",
    "        x = self.global_pool(x)              # (B, 256, 1)\n",
    "        x = x.squeeze(-1)                    # (B, 256)\n",
    "        x = self.fc(x)                       # (B, feat_dim)\n",
    "        return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550e86a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECG SMEE params: 22464\n",
      "MCG SMEE params: 24640\n",
      "Shapes: torch.Size([4, 256]) torch.Size([4, 256])\n"
     ]
    }
   ],
   "source": [
    "#from models import ECGEncoderSMEE, MCGEncoderSMEE  \n",
    "import torch\n",
    "\n",
    "def count_params(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "ecg_smee = ECGEncoderSMEE(in_channels=32)\n",
    "mcg_smee = MCGEncoderSMEE(in_channels=100)\n",
    "\n",
    "print(\"ECG SMEE params:\", count_params(ecg_smee))\n",
    "print(\"MCG SMEE params:\", count_params(mcg_smee))\n",
    "\n",
    "# quick forward test\n",
    "x_ecg = torch.randn(4, 32, 2000)\n",
    "x_mcg = torch.randn(4, 100, 2000)\n",
    "h_e = ecg_smee(x_ecg)\n",
    "h_m = mcg_smee(x_mcg)\n",
    "print(\"Shapes:\", h_e.shape, h_m.shape)  # should be: torch.Size([4, 256]) torch.Size([4, 256])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a41f653",
   "metadata": {},
   "source": [
    "# Projection Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bff868b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class ProjectionHead(nn.Module):\n",
    "    \"\"\"\n",
    "    2-layer MLP projection head.\n",
    "    Input: (B, feat_dim)\n",
    "    Output: (B, proj_dim) normalized\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim=256, proj_dim=128):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_dim, in_dim)\n",
    "        self.fc2 = nn.Linear(in_dim, proj_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = F.normalize(x, p=2, dim=-1)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "def cross_modal_info_nce(z_e, z_m, temperature=0.1):\n",
    "    \"\"\"\n",
    "    Cross-modal InfoNCE loss between ECG (z_e) and MCG (z_m).\n",
    "    z_e: (B, D) ECG embeddings (L2-normalized)\n",
    "    z_m: (B, D) MCG embeddings (L2-normalized)\n",
    "\n",
    "    We compute similarity matrix S = z_e @ z_m^T / T\n",
    "    and use symmetric loss: ECG→MCG and MCG→ECG.\n",
    "    \"\"\"\n",
    "    assert z_e.shape == z_m.shape\n",
    "    B, D = z_e.shape\n",
    "\n",
    "    # cosine similarity (since both are normalized, dot = cos)\n",
    "    logits = z_e @ z_m.T / temperature  # (B, B)\n",
    "\n",
    "    targets = torch.arange(B, device=z_e.device)\n",
    "\n",
    "    # ECG→MCG\n",
    "    loss_e2m = F.cross_entropy(logits, targets)\n",
    "\n",
    "    # MCG→ECG (transpose)\n",
    "    loss_m2e = F.cross_entropy(logits.T, targets)\n",
    "\n",
    "    loss = 0.5 * (loss_e2m + loss_m2e)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbabde47",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e66b5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def simclr_nt_xent_loss(z1, z2, temperature=0.1):\n",
    "    \"\"\"\n",
    "    z1, z2: (B, D) normalized embeddings from two views of the same batch.\n",
    "    Returns scalar loss.\n",
    "    \"\"\"\n",
    "    assert z1.shape == z2.shape\n",
    "    batch_size = z1.shape[0]\n",
    "\n",
    "    z = torch.cat([z1, z2], dim=0)  # (2B, D)\n",
    "    sim = F.cosine_similarity(z.unsqueeze(1), z.unsqueeze(0), dim=-1)  # (2B, 2B)\n",
    "\n",
    "    # Mask to remove self-similarity\n",
    "    self_mask = torch.eye(2 * batch_size, dtype=torch.bool, device=z.device)\n",
    "    sim = sim / temperature\n",
    "\n",
    "    # For each anchor i in 0..2B-1, define positives and negatives\n",
    "    # Positives: (i, i+B) or (i, i-B) depending on which half\n",
    "    labels = torch.arange(2 * batch_size, device=z.device)\n",
    "    labels = (labels + batch_size) % (2 * batch_size)  # positive index for each anchor\n",
    "\n",
    "    # For cross-entropy, we need logits (2B, 2B-1) and labels\n",
    "    sim = sim.masked_fill(self_mask, -1e9)\n",
    "\n",
    "    loss = F.cross_entropy(sim, labels)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c001621c",
   "metadata": {},
   "source": [
    "## New LOss :ECG↔MCG contrastive loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ec9b27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a655ef64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def simclr_nt_xent_loss(z1, z2, temperature=0.1):\n",
    "    \"\"\"\n",
    "    Standard NT-Xent (SimCLR) loss for two views.\n",
    "    z1, z2: (B, D) L2-normalized embeddings.\n",
    "    \"\"\"\n",
    "    assert z1.shape == z2.shape\n",
    "    B = z1.shape[0]\n",
    "\n",
    "    z = torch.cat([z1, z2], dim=0)  # (2B, D)\n",
    "    sim = F.cosine_similarity(z.unsqueeze(1), z.unsqueeze(0), dim=-1)  # (2B, 2B)\n",
    "    sim = sim / temperature\n",
    "\n",
    "    labels = torch.arange(2 * B, device=z.device)\n",
    "    labels = (labels + B) % (2 * B)  # positive for each index is the other view\n",
    "\n",
    "    # mask self-similarities\n",
    "    mask = torch.eye(2 * B, dtype=torch.bool, device=z.device)\n",
    "    sim = sim.masked_fill(mask, -1e9)\n",
    "\n",
    "    loss = F.cross_entropy(sim, labels)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def cross_modal_info_nce(z_e, z_m, temperature=0.1):\n",
    "    \"\"\"\n",
    "    Symmetric cross-modal InfoNCE between ECG (z_e) and MCG (z_m).\n",
    "    z_e, z_m: (B, D) L2-normalized.\n",
    "    \"\"\"\n",
    "    B = z_e.shape[0]\n",
    "    logits = z_e @ z_m.T / temperature  # (B, B)\n",
    "    targets = torch.arange(B, device=z_e.device)\n",
    "\n",
    "    loss_e2m = F.cross_entropy(logits, targets)\n",
    "    loss_m2e = F.cross_entropy(logits.T, targets)\n",
    "    return 0.5 * (loss_e2m + loss_m2e)\n",
    "\n",
    "\n",
    "def ecg_mcg_contrastive_loss(\n",
    "    z_e, z_m,\n",
    "    z_e_aug1=None, z_e_aug2=None,\n",
    "    z_m_aug1=None, z_m_aug2=None,\n",
    "    temperature=0.1,\n",
    "    lambda_within=0.1,\n",
    "):\n",
    "    \"\"\"\n",
    "    Task-specific ECG<->MCG loss:\n",
    "\n",
    "    L_total = L_cross(ECG, MCG) + λ (L_within_ECG + L_within_MCG)\n",
    "\n",
    "    z_e, z_m: (B, D) main ECG/MCG embeddings\n",
    "    z_e_aug1, z_e_aug2: (B, D) augmented ECG embeddings\n",
    "    z_m_aug1, z_m_aug2: (B, D) augmented MCG embeddings\n",
    "    \"\"\"\n",
    "    # cross-modal alignment\n",
    "    loss = cross_modal_info_nce(z_e, z_m, temperature=temperature)\n",
    "\n",
    "    # within-ECG consistency\n",
    "    if (z_e_aug1 is not None) and (z_e_aug2 is not None):\n",
    "        loss_ecg = simclr_nt_xent_loss(z_e_aug1, z_e_aug2, temperature=temperature)\n",
    "        loss = loss + lambda_within * loss_ecg\n",
    "\n",
    "    # within-MCG consistency\n",
    "    if (z_m_aug1 is not None) and (z_m_aug2 is not None):\n",
    "        loss_mcg = simclr_nt_xent_loss(z_m_aug1, z_m_aug2, temperature=temperature)\n",
    "        loss = loss + lambda_within * loss_mcg\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50912204",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c23991e",
   "metadata": {},
   "source": [
    "# train_koch_crossmodal_smee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473fada4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch 001/50 - SMEE cross-modal loss: 2.0827\n",
      "Epoch 002/50 - SMEE cross-modal loss: 2.0606\n",
      "Epoch 003/50 - SMEE cross-modal loss: 2.0716\n",
      "Epoch 004/50 - SMEE cross-modal loss: 2.0653\n",
      "Epoch 005/50 - SMEE cross-modal loss: 2.0598\n",
      "Epoch 006/50 - SMEE cross-modal loss: 2.0424\n",
      "Epoch 007/50 - SMEE cross-modal loss: 2.0075\n",
      "Epoch 008/50 - SMEE cross-modal loss: 1.9159\n",
      "Epoch 009/50 - SMEE cross-modal loss: 2.0060\n",
      "Epoch 010/50 - SMEE cross-modal loss: 1.9069\n",
      "Epoch 011/50 - SMEE cross-modal loss: 1.7929\n",
      "Epoch 012/50 - SMEE cross-modal loss: 1.8310\n",
      "Epoch 013/50 - SMEE cross-modal loss: 1.8830\n",
      "Epoch 014/50 - SMEE cross-modal loss: 1.6852\n",
      "Epoch 015/50 - SMEE cross-modal loss: 1.5853\n",
      "Epoch 016/50 - SMEE cross-modal loss: 1.5584\n",
      "Epoch 017/50 - SMEE cross-modal loss: 1.4793\n",
      "Epoch 018/50 - SMEE cross-modal loss: 1.5021\n",
      "Epoch 019/50 - SMEE cross-modal loss: 1.5005\n",
      "Epoch 020/50 - SMEE cross-modal loss: 1.3316\n",
      "Epoch 021/50 - SMEE cross-modal loss: 1.3059\n",
      "Epoch 022/50 - SMEE cross-modal loss: 1.1494\n",
      "Epoch 023/50 - SMEE cross-modal loss: 1.2602\n",
      "Epoch 024/50 - SMEE cross-modal loss: 1.1988\n",
      "Epoch 025/50 - SMEE cross-modal loss: 1.1297\n",
      "Epoch 026/50 - SMEE cross-modal loss: 1.0990\n",
      "Epoch 027/50 - SMEE cross-modal loss: 1.1835\n",
      "Epoch 028/50 - SMEE cross-modal loss: 1.1615\n",
      "Epoch 029/50 - SMEE cross-modal loss: 0.9565\n",
      "Epoch 030/50 - SMEE cross-modal loss: 1.1778\n",
      "Epoch 031/50 - SMEE cross-modal loss: 1.0456\n",
      "Epoch 032/50 - SMEE cross-modal loss: 1.0489\n",
      "Epoch 033/50 - SMEE cross-modal loss: 0.9247\n",
      "Epoch 034/50 - SMEE cross-modal loss: 0.7807\n",
      "Epoch 035/50 - SMEE cross-modal loss: 0.9539\n",
      "Epoch 036/50 - SMEE cross-modal loss: 0.8906\n",
      "Epoch 037/50 - SMEE cross-modal loss: 0.9339\n",
      "Epoch 038/50 - SMEE cross-modal loss: 0.6797\n",
      "Epoch 039/50 - SMEE cross-modal loss: 0.7274\n",
      "Epoch 040/50 - SMEE cross-modal loss: 0.8549\n",
      "Epoch 041/50 - SMEE cross-modal loss: 0.7116\n",
      "Epoch 042/50 - SMEE cross-modal loss: 0.7944\n",
      "Epoch 043/50 - SMEE cross-modal loss: 0.6810\n",
      "Epoch 044/50 - SMEE cross-modal loss: 0.6290\n",
      "Epoch 045/50 - SMEE cross-modal loss: 0.6047\n",
      "Epoch 046/50 - SMEE cross-modal loss: 0.6097\n",
      "Epoch 047/50 - SMEE cross-modal loss: 0.7297\n",
      "Epoch 048/50 - SMEE cross-modal loss: 0.6175\n",
      "Epoch 049/50 - SMEE cross-modal loss: 0.5569\n",
      "Epoch 050/50 - SMEE cross-modal loss: 0.5761\n",
      "Saved SMEE-based ECG + MCG encoders and projection heads (Koch dataset)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "#from koch_dataset import KochPairedBeatsDataset\n",
    "#from models import (ECGEncoderSMEE,MCGEncoderSMEE,ProjectionHead, cross_modal_info_nce,   )\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_koch_crossmodal_smee(\n",
    "    npz_path=\"koch_pairs.npz\",\n",
    "    batch_size=8,\n",
    "    lr=1e-3,\n",
    "    epochs=50,\n",
    "    device=\"cpu\",\n",
    "):\n",
    "    # 1) Dataset & DataLoader\n",
    "    dataset = KochPairedBeatsDataset(npz_path=npz_path, augment=True)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "    # 2) New encoders: SMEE-based ECG (32 ch) & MCG (100 ch)\n",
    "    #    (no shared backbone yet, we keep it simple first)\n",
    "    ecg_encoder = ECGEncoderSMEE(in_channels=32, bottleneck_channels=32, feat_dim=256)\n",
    "    mcg_encoder = MCGEncoderSMEE(in_channels=100, bottleneck_channels=32, feat_dim=256)\n",
    "\n",
    "    ecg_proj = ProjectionHead(in_dim=256, proj_dim=128)\n",
    "    mcg_proj = ProjectionHead(in_dim=256, proj_dim=128)\n",
    "\n",
    "    ecg_encoder.to(device)\n",
    "    mcg_encoder.to(device)\n",
    "    ecg_proj.to(device)\n",
    "    mcg_proj.to(device)\n",
    "\n",
    "    # 3) Optimizer\n",
    "    params = (\n",
    "        list(ecg_encoder.parameters())\n",
    "        + list(mcg_encoder.parameters())\n",
    "        + list(ecg_proj.parameters())\n",
    "        + list(mcg_proj.parameters())\n",
    "    )\n",
    "    optimizer = torch.optim.AdamW(params, lr=lr, weight_decay=1e-4)\n",
    "\n",
    "    # 4) Training loop\n",
    "    ecg_encoder.train()\n",
    "    mcg_encoder.train()\n",
    "    ecg_proj.train()\n",
    "    mcg_proj.train()\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for step, (ecg, mcg) in enumerate(loader):\n",
    "            ecg = ecg.to(device)  # (B, 32, 2000)\n",
    "            mcg = mcg.to(device)  # (B, 100, 2000)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Encode\n",
    "            h_e = ecg_encoder(ecg)   # (B, 256)\n",
    "            h_m = mcg_encoder(mcg)   # (B, 256)\n",
    "\n",
    "            # Project\n",
    "            z_e = ecg_proj(h_e)      # (B, 128)\n",
    "            z_m = mcg_proj(h_m)      # (B, 128)\n",
    "\n",
    "            # Cross-modal InfoNCE\n",
    "            loss = cross_modal_info_nce(z_e, z_m, temperature=0.1)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_loss = running_loss / (step + 1)\n",
    "        print(f\"Epoch {epoch:03d}/{epochs} - SMEE cross-modal loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # 5) Save new model weights\n",
    "    torch.save(ecg_encoder.state_dict(), \"ecg_encoder_koch_smee.pth\")\n",
    "    torch.save(mcg_encoder.state_dict(), \"mcg_encoder_koch_smee.pth\")\n",
    "    torch.save(ecg_proj.state_dict(), \"ecg_proj_koch_smee.pth\")\n",
    "    torch.save(mcg_proj.state_dict(), \"mcg_proj_koch_smee.pth\")\n",
    "    print(\"Saved SMEE-based ECG + MCG encoders and projection heads (Koch dataset)\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(\"Using device:\", device)\n",
    "\n",
    "    train_koch_crossmodal_smee(\n",
    "        npz_path=\"koch_pairs.npz\",\n",
    "        batch_size=8,\n",
    "        lr=1e-3,\n",
    "        epochs=50, \n",
    "        device=device,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134aa9df",
   "metadata": {},
   "source": [
    "## Train with new loss:ECG↔MCG contrastive loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ddefed8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch 001/50 - SMEE ECG<->MCG loss: 2.5535 (λ_within=0.1)\n",
      "Epoch 002/50 - SMEE ECG<->MCG loss: 2.2967 (λ_within=0.1)\n",
      "Epoch 003/50 - SMEE ECG<->MCG loss: 2.1071 (λ_within=0.1)\n",
      "Epoch 004/50 - SMEE ECG<->MCG loss: 2.0618 (λ_within=0.1)\n",
      "Epoch 005/50 - SMEE ECG<->MCG loss: 1.6499 (λ_within=0.1)\n",
      "Epoch 006/50 - SMEE ECG<->MCG loss: 1.6335 (λ_within=0.1)\n",
      "Epoch 007/50 - SMEE ECG<->MCG loss: 1.4556 (λ_within=0.1)\n",
      "Epoch 008/50 - SMEE ECG<->MCG loss: 1.2041 (λ_within=0.1)\n",
      "Epoch 009/50 - SMEE ECG<->MCG loss: 1.0939 (λ_within=0.1)\n",
      "Epoch 010/50 - SMEE ECG<->MCG loss: 1.1297 (λ_within=0.1)\n",
      "Epoch 011/50 - SMEE ECG<->MCG loss: 1.1095 (λ_within=0.1)\n",
      "Epoch 012/50 - SMEE ECG<->MCG loss: 0.7167 (λ_within=0.1)\n",
      "Epoch 013/50 - SMEE ECG<->MCG loss: 0.9641 (λ_within=0.1)\n",
      "Epoch 014/50 - SMEE ECG<->MCG loss: 0.8343 (λ_within=0.1)\n",
      "Epoch 015/50 - SMEE ECG<->MCG loss: 0.5815 (λ_within=0.1)\n",
      "Epoch 016/50 - SMEE ECG<->MCG loss: 0.5014 (λ_within=0.1)\n",
      "Epoch 017/50 - SMEE ECG<->MCG loss: 0.4769 (λ_within=0.1)\n",
      "Epoch 018/50 - SMEE ECG<->MCG loss: 0.5594 (λ_within=0.1)\n",
      "Epoch 019/50 - SMEE ECG<->MCG loss: 0.7079 (λ_within=0.1)\n",
      "Epoch 020/50 - SMEE ECG<->MCG loss: 0.7366 (λ_within=0.1)\n",
      "Epoch 021/50 - SMEE ECG<->MCG loss: 0.6432 (λ_within=0.1)\n",
      "Epoch 022/50 - SMEE ECG<->MCG loss: 0.5679 (λ_within=0.1)\n",
      "Epoch 023/50 - SMEE ECG<->MCG loss: 0.4324 (λ_within=0.1)\n",
      "Epoch 024/50 - SMEE ECG<->MCG loss: 0.3138 (λ_within=0.1)\n",
      "Epoch 025/50 - SMEE ECG<->MCG loss: 0.2960 (λ_within=0.1)\n",
      "Epoch 026/50 - SMEE ECG<->MCG loss: 0.3044 (λ_within=0.1)\n",
      "Epoch 027/50 - SMEE ECG<->MCG loss: 0.3185 (λ_within=0.1)\n",
      "Epoch 028/50 - SMEE ECG<->MCG loss: 0.2899 (λ_within=0.1)\n",
      "Epoch 029/50 - SMEE ECG<->MCG loss: 0.2161 (λ_within=0.1)\n",
      "Epoch 030/50 - SMEE ECG<->MCG loss: 0.2742 (λ_within=0.1)\n",
      "Epoch 031/50 - SMEE ECG<->MCG loss: 0.1804 (λ_within=0.1)\n",
      "Epoch 032/50 - SMEE ECG<->MCG loss: 0.1951 (λ_within=0.1)\n",
      "Epoch 033/50 - SMEE ECG<->MCG loss: 0.1625 (λ_within=0.1)\n",
      "Epoch 034/50 - SMEE ECG<->MCG loss: 0.1814 (λ_within=0.1)\n",
      "Epoch 035/50 - SMEE ECG<->MCG loss: 0.1574 (λ_within=0.1)\n",
      "Epoch 036/50 - SMEE ECG<->MCG loss: 0.1382 (λ_within=0.1)\n",
      "Epoch 037/50 - SMEE ECG<->MCG loss: 0.1429 (λ_within=0.1)\n",
      "Epoch 038/50 - SMEE ECG<->MCG loss: 0.0913 (λ_within=0.1)\n",
      "Epoch 039/50 - SMEE ECG<->MCG loss: 0.1103 (λ_within=0.1)\n",
      "Epoch 040/50 - SMEE ECG<->MCG loss: 0.1149 (λ_within=0.1)\n",
      "Epoch 041/50 - SMEE ECG<->MCG loss: 0.1209 (λ_within=0.1)\n",
      "Epoch 042/50 - SMEE ECG<->MCG loss: 0.0930 (λ_within=0.1)\n",
      "Epoch 043/50 - SMEE ECG<->MCG loss: 0.0770 (λ_within=0.1)\n",
      "Epoch 044/50 - SMEE ECG<->MCG loss: 0.0637 (λ_within=0.1)\n",
      "Epoch 045/50 - SMEE ECG<->MCG loss: 0.0802 (λ_within=0.1)\n",
      "Epoch 046/50 - SMEE ECG<->MCG loss: 0.1217 (λ_within=0.1)\n",
      "Epoch 047/50 - SMEE ECG<->MCG loss: 0.2668 (λ_within=0.1)\n",
      "Epoch 048/50 - SMEE ECG<->MCG loss: 0.3337 (λ_within=0.1)\n",
      "Epoch 049/50 - SMEE ECG<->MCG loss: 0.3696 (λ_within=0.1)\n",
      "Epoch 050/50 - SMEE ECG<->MCG loss: 0.2544 (λ_within=0.1)\n",
      "Saved SMEE ECG+MCG encoders with ECG<->MCG-specific loss.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def augment_signal(x, noise_std=0.01, max_shift=20):\n",
    "    \"\"\"\n",
    "    x: (B, C, T) tensor\n",
    "    Adds small Gaussian noise and a tiny circular time shift.\n",
    "    \"\"\"\n",
    "    # small Gaussian noise\n",
    "    x = x + noise_std * torch.randn_like(x)\n",
    "\n",
    "    # random circular shift along time dimension\n",
    "    if max_shift > 0:\n",
    "        shift = torch.randint(-max_shift, max_shift + 1, (1,)).item()\n",
    "        if shift != 0:\n",
    "            x = torch.roll(x, shifts=shift, dims=-1)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "#from koch_dataset import KochPairedBeatsDataset\n",
    "# models import (\n",
    "#ECGEncoderSMEE,\n",
    "#    MCGEncoderSMEE,\n",
    "#    ProjectionHead,\n",
    "#ecg_mcg_contrastive_loss,\n",
    "#)\n",
    "#from train_utils import augment_signal  # or paste augment_signal in this file\n",
    "\n",
    "\n",
    "def train_koch_crossmodal_smee_ecgmcg_loss(\n",
    "    npz_path=\"koch_pairs.npz\",\n",
    "    batch_size=8,\n",
    "    lr=1e-3,\n",
    "    epochs=50,\n",
    "    device=\"cpu\",\n",
    "    temperature=0.1,\n",
    "    lambda_within=0.1,\n",
    "):\n",
    "    # 1) Dataset (we can keep augment=False; we handle aug in the loop)\n",
    "    dataset = KochPairedBeatsDataset(npz_path=npz_path, augment=False)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "    # 2) New SMEE encoders\n",
    "    ecg_encoder = ECGEncoderSMEE(in_channels=32, bottleneck_channels=32, feat_dim=256)\n",
    "    mcg_encoder = MCGEncoderSMEE(in_channels=100, bottleneck_channels=32, feat_dim=256)\n",
    "\n",
    "    ecg_proj = ProjectionHead(in_dim=256, proj_dim=128)\n",
    "    mcg_proj = ProjectionHead(in_dim=256, proj_dim=128)\n",
    "\n",
    "    ecg_encoder.to(device)\n",
    "    mcg_encoder.to(device)\n",
    "    ecg_proj.to(device)\n",
    "    mcg_proj.to(device)\n",
    "\n",
    "    params = (\n",
    "        list(ecg_encoder.parameters())\n",
    "        + list(mcg_encoder.parameters())\n",
    "        + list(ecg_proj.parameters())\n",
    "        + list(mcg_proj.parameters())\n",
    "    )\n",
    "    optimizer = torch.optim.AdamW(params, lr=lr, weight_decay=1e-4)\n",
    "\n",
    "    ecg_encoder.train()\n",
    "    mcg_encoder.train()\n",
    "    ecg_proj.train()\n",
    "    mcg_proj.train()\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for step, (ecg, mcg) in enumerate(loader):\n",
    "            ecg = ecg.to(device)  # (B, 32, 2000)\n",
    "            mcg = mcg.to(device)  # (B, 100, 2000)\n",
    "\n",
    "            # Create augmentations for within-modal SimCLR terms\n",
    "            ecg1 = augment_signal(ecg.clone())\n",
    "            ecg2 = augment_signal(ecg.clone())\n",
    "            mcg1 = augment_signal(mcg.clone())\n",
    "            mcg2 = augment_signal(mcg.clone())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # --- Original (for cross-modal) ---\n",
    "            h_e = ecg_encoder(ecg)   # (B, 256)\n",
    "            h_m = mcg_encoder(mcg)   # (B, 256)\n",
    "            z_e = ecg_proj(h_e)      # (B, 128)\n",
    "            z_m = mcg_proj(h_m)      # (B, 128)\n",
    "\n",
    "            # --- Augmented ECG ---\n",
    "            h_e1 = ecg_encoder(ecg1)\n",
    "            h_e2 = ecg_encoder(ecg2)\n",
    "            z_e1 = ecg_proj(h_e1)\n",
    "            z_e2 = ecg_proj(h_e2)\n",
    "\n",
    "            # --- Augmented MCG ---\n",
    "            h_m1 = mcg_encoder(mcg1)\n",
    "            h_m2 = mcg_encoder(mcg2)\n",
    "            z_m1 = mcg_proj(h_m1)\n",
    "            z_m2 = mcg_proj(h_m2)\n",
    "\n",
    "            # New ECG<->MCG-specific loss\n",
    "            loss = ecg_mcg_contrastive_loss(\n",
    "                z_e, z_m,\n",
    "                z_e_aug1=z_e1, z_e_aug2=z_e2,\n",
    "                z_m_aug1=z_m1, z_m_aug2=z_m2,\n",
    "                temperature=temperature,\n",
    "                lambda_within=lambda_within,\n",
    "            )\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_loss = running_loss / (step + 1)\n",
    "        print(\n",
    "            f\"Epoch {epoch:03d}/{epochs} - SMEE ECG<->MCG loss: \"\n",
    "            f\"{avg_loss:.4f} (λ_within={lambda_within})\"\n",
    "        )\n",
    "\n",
    "    # Save under new names so you keep the old SMEE model as well\n",
    "    torch.save(ecg_encoder.state_dict(), \"ecg_encoder_koch_smee_loss.pth\")\n",
    "    torch.save(mcg_encoder.state_dict(), \"mcg_encoder_koch_smee_loss.pth\")\n",
    "    torch.save(ecg_proj.state_dict(), \"ecg_proj_koch_smee_loss.pth\")\n",
    "    torch.save(mcg_proj.state_dict(), \"mcg_proj_koch_smee_loss.pth\")\n",
    "    print(\"Saved SMEE ECG+MCG encoders with ECG<->MCG-specific loss.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(\"Using device:\", device)\n",
    "    train_koch_crossmodal_smee_ecgmcg_loss(\n",
    "        npz_path=\"koch_pairs.npz\",\n",
    "        batch_size=8,\n",
    "        lr=1e-3,\n",
    "        epochs=50,\n",
    "        device=device,\n",
    "        temperature=0.1,\n",
    "        lambda_within=0.1,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d885996",
   "metadata": {},
   "source": [
    "# eval script for SMEE model for koch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e18d069",
   "metadata": {},
   "source": [
    "## New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2310e2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Total beats: 127\n",
      "SMEE ECG→MCG top-1 retrieval:  18.90%\n",
      "SMEE MCG→ECG top-1 retrieval:  19.69%\n",
      "SMEE ECG→MCG top-5 retrieval: 72.44%\n",
      "SMEE MCG→ECG top-5 retrieval: 58.27%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "#from koch_dataset import KochPairedBeatsDataset\n",
    "#from models import ECGEncoderSMEE, MCGEncoderSMEE, ProjectionHead\n",
    "\n",
    "\n",
    "def eval_koch_retrieval_smee(\n",
    "    npz_path=\"koch_pairs.npz\",\n",
    "    ecg_encoder_path=\"ecg_encoder_koch_smee.pth\",\n",
    "    mcg_encoder_path=\"mcg_encoder_koch_smee.pth\",\n",
    "    ecg_proj_path=\"ecg_proj_koch_smee.pth\",\n",
    "    mcg_proj_path=\"mcg_proj_koch_smee.pth\",\n",
    "    batch_size=64,\n",
    "    device=\"cpu\",\n",
    "):\n",
    "    # 1) Dataset (no augmentation)\n",
    "    dataset = KochPairedBeatsDataset(npz_path=npz_path, augment=False)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "    # 2) Rebuild SMEE encoders + projection heads\n",
    "    ecg_encoder = ECGEncoderSMEE(in_channels=32, bottleneck_channels=32, feat_dim=256)\n",
    "    mcg_encoder = MCGEncoderSMEE(in_channels=100, bottleneck_channels=32, feat_dim=256)\n",
    "\n",
    "    ecg_proj = ProjectionHead(in_dim=256, proj_dim=128)\n",
    "    mcg_proj = ProjectionHead(in_dim=256, proj_dim=128)\n",
    "\n",
    "    # Load weights\n",
    "    ecg_encoder.load_state_dict(torch.load(ecg_encoder_path, map_location=\"cpu\"))\n",
    "    mcg_encoder.load_state_dict(torch.load(mcg_encoder_path, map_location=\"cpu\"))\n",
    "    ecg_proj.load_state_dict(torch.load(ecg_proj_path, map_location=\"cpu\"))\n",
    "    mcg_proj.load_state_dict(torch.load(mcg_proj_path, map_location=\"cpu\"))\n",
    "\n",
    "    ecg_encoder.to(device).eval()\n",
    "    mcg_encoder.to(device).eval()\n",
    "    ecg_proj.to(device).eval()\n",
    "    mcg_proj.to(device).eval()\n",
    "\n",
    "    # 3) Compute embeddings for all beats\n",
    "    all_z_e = []\n",
    "    all_z_m = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for ecg, mcg in loader:\n",
    "            ecg = ecg.to(device)  # (B, 32, 2000)\n",
    "            mcg = mcg.to(device)  # (B, 100, 2000)\n",
    "\n",
    "            h_e = ecg_encoder(ecg)   # (B, 256)\n",
    "            h_m = mcg_encoder(mcg)   # (B, 256)\n",
    "\n",
    "            z_e = ecg_proj(h_e)      # (B, 128)\n",
    "            z_m = mcg_proj(h_m)      # (B, 128)\n",
    "\n",
    "            all_z_e.append(z_e.cpu())\n",
    "            all_z_m.append(z_m.cpu())\n",
    "\n",
    "    z_e = torch.cat(all_z_e, dim=0)  # (N, 128)\n",
    "    z_m = torch.cat(all_z_m, dim=0)  # (N, 128)\n",
    "    N = z_e.shape[0]\n",
    "    print(f\"Total beats: {N}\")\n",
    "\n",
    "    # 4) Cosine similarity matrix\n",
    "    sim = z_e @ z_m.T  # (N, N), embeddings already L2-normalized\n",
    "\n",
    "    # ECG -> MCG top-1\n",
    "    preds_e2m = sim.argmax(dim=1)\n",
    "    correct_e2m = (preds_e2m == torch.arange(N)).float().mean().item()\n",
    "\n",
    "    # MCG -> ECG top-1\n",
    "    preds_m2e = sim.argmax(dim=0)\n",
    "    correct_m2e = (preds_m2e == torch.arange(N)).float().mean().item()\n",
    "\n",
    "    # ECG -> MCG top-5\n",
    "    topk = 5\n",
    "    topk_e2m = sim.topk(topk, dim=1).indices  # (N, K)\n",
    "    correct_topk_e2m = (\n",
    "        (topk_e2m == torch.arange(N).unsqueeze(1)).any(dim=1).float().mean().item()\n",
    "    )\n",
    "\n",
    "    # MCG -> ECG top-5\n",
    "    topk_m2e = sim.topk(topk, dim=0).indices  # (K, N)\n",
    "    correct_topk_m2e = (\n",
    "        (topk_m2e == torch.arange(N).unsqueeze(0)).any(dim=0).float().mean().item()\n",
    "    )\n",
    "\n",
    "    print(f\"SMEE ECG→MCG top-1 retrieval:  {correct_e2m*100:.2f}%\")\n",
    "    print(f\"SMEE MCG→ECG top-1 retrieval:  {correct_m2e*100:.2f}%\")\n",
    "    print(f\"SMEE ECG→MCG top-{topk} retrieval: {correct_topk_e2m*100:.2f}%\")\n",
    "    print(f\"SMEE MCG→ECG top-{topk} retrieval: {correct_topk_m2e*100:.2f}%\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(\"Using device:\", device)\n",
    "    eval_koch_retrieval_smee(device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9735857",
   "metadata": {},
   "source": [
    "## New Loss: ECG↔MCG contrastive loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0f2f7a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Total beats: 127\n",
      "SMEE ECG→MCG top-1 retrieval:  59.06%\n",
      "SMEE MCG→ECG top-1 retrieval:  56.69%\n",
      "SMEE ECG→MCG top-5 retrieval: 95.28%\n",
      "SMEE MCG→ECG top-5 retrieval: 91.34%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "#from koch_dataset import KochPairedBeatsDataset\n",
    "#from models import ECGEncoderSMEE, MCGEncoderSMEE, ProjectionHead\n",
    "\n",
    "\n",
    "def eval_koch_retrieval_smee(\n",
    "    npz_path=\"koch_pairs.npz\",\n",
    "    ecg_encoder_path=\"ecg_encoder_koch_smee_loss.pth\",\n",
    "    mcg_encoder_path=\"mcg_encoder_koch_smee_loss.pth\",\n",
    "    ecg_proj_path=\"ecg_proj_koch_smee_loss.pth\",\n",
    "    mcg_proj_path=\"mcg_proj_koch_smee_loss.pth\",\n",
    "    batch_size=64,\n",
    "    device=\"cpu\",\n",
    "):\n",
    "    # 1) Dataset (no augmentation)\n",
    "    dataset = KochPairedBeatsDataset(npz_path=npz_path, augment=False)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "    # 2) Rebuild SMEE encoders + projection heads\n",
    "    ecg_encoder = ECGEncoderSMEE(in_channels=32, bottleneck_channels=32, feat_dim=256)\n",
    "    mcg_encoder = MCGEncoderSMEE(in_channels=100, bottleneck_channels=32, feat_dim=256)\n",
    "\n",
    "    ecg_proj = ProjectionHead(in_dim=256, proj_dim=128)\n",
    "    mcg_proj = ProjectionHead(in_dim=256, proj_dim=128)\n",
    "\n",
    "    # Load weights\n",
    "    ecg_encoder.load_state_dict(torch.load(ecg_encoder_path, map_location=\"cpu\"))\n",
    "    mcg_encoder.load_state_dict(torch.load(mcg_encoder_path, map_location=\"cpu\"))\n",
    "    ecg_proj.load_state_dict(torch.load(ecg_proj_path, map_location=\"cpu\"))\n",
    "    mcg_proj.load_state_dict(torch.load(mcg_proj_path, map_location=\"cpu\"))\n",
    "\n",
    "    ecg_encoder.to(device).eval()\n",
    "    mcg_encoder.to(device).eval()\n",
    "    ecg_proj.to(device).eval()\n",
    "    mcg_proj.to(device).eval()\n",
    "\n",
    "    # 3) Compute embeddings for all beats\n",
    "    all_z_e = []\n",
    "    all_z_m = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for ecg, mcg in loader:\n",
    "            ecg = ecg.to(device)  # (B, 32, 2000)\n",
    "            mcg = mcg.to(device)  # (B, 100, 2000)\n",
    "\n",
    "            h_e = ecg_encoder(ecg)   # (B, 256)\n",
    "            h_m = mcg_encoder(mcg)   # (B, 256)\n",
    "\n",
    "            z_e = ecg_proj(h_e)      # (B, 128)\n",
    "            z_m = mcg_proj(h_m)      # (B, 128)\n",
    "\n",
    "            all_z_e.append(z_e.cpu())\n",
    "            all_z_m.append(z_m.cpu())\n",
    "\n",
    "    z_e = torch.cat(all_z_e, dim=0)  # (N, 128)\n",
    "    z_m = torch.cat(all_z_m, dim=0)  # (N, 128)\n",
    "    N = z_e.shape[0]\n",
    "    print(f\"Total beats: {N}\")\n",
    "\n",
    "    # 4) Cosine similarity matrix\n",
    "    sim = z_e @ z_m.T  # (N, N), embeddings already L2-normalized\n",
    "\n",
    "    # ECG -> MCG top-1\n",
    "    preds_e2m = sim.argmax(dim=1)\n",
    "    correct_e2m = (preds_e2m == torch.arange(N)).float().mean().item()\n",
    "\n",
    "    # MCG -> ECG top-1\n",
    "    preds_m2e = sim.argmax(dim=0)\n",
    "    correct_m2e = (preds_m2e == torch.arange(N)).float().mean().item()\n",
    "\n",
    "    # ECG -> MCG top-5\n",
    "    topk = 5\n",
    "    topk_e2m = sim.topk(topk, dim=1).indices  # (N, K)\n",
    "    correct_topk_e2m = (\n",
    "        (topk_e2m == torch.arange(N).unsqueeze(1)).any(dim=1).float().mean().item()\n",
    "    )\n",
    "\n",
    "    # MCG -> ECG top-5\n",
    "    topk_m2e = sim.topk(topk, dim=0).indices  # (K, N)\n",
    "    correct_topk_m2e = (\n",
    "        (topk_m2e == torch.arange(N).unsqueeze(0)).any(dim=0).float().mean().item()\n",
    "    )\n",
    "\n",
    "    print(f\"SMEE ECG→MCG top-1 retrieval:  {correct_e2m*100:.2f}%\")\n",
    "    print(f\"SMEE MCG→ECG top-1 retrieval:  {correct_m2e*100:.2f}%\")\n",
    "    print(f\"SMEE ECG→MCG top-{topk} retrieval: {correct_topk_e2m*100:.2f}%\")\n",
    "    print(f\"SMEE MCG→ECG top-{topk} retrieval: {correct_topk_m2e*100:.2f}%\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(\"Using device:\", device)\n",
    "    eval_koch_retrieval_smee(device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7585dcc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old ECG encoder params: 483648\n",
      "Old MCG encoder params: 514112\n",
      "New ECG SMEE params: 22464\n",
      "New MCG SMEE params: 24640\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "#from models import Conv1DEncoder, ECGEncoderSMEE, MCGEncoderSMEE\n",
    "\n",
    "def count_params(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# Old baseline encoders (what you used first on Koch)\n",
    "old_ecg = Conv1DEncoder(in_channels=32, feat_dim=256)\n",
    "old_mcg = Conv1DEncoder(in_channels=100, feat_dim=256)\n",
    "\n",
    "# New SMEE encoders\n",
    "new_ecg = ECGEncoderSMEE(in_channels=32, bottleneck_channels=32, feat_dim=256)\n",
    "new_mcg = MCGEncoderSMEE(in_channels=100, bottleneck_channels=32, feat_dim=256)\n",
    "\n",
    "print(\"Old ECG encoder params:\", count_params(old_ecg))\n",
    "print(\"Old MCG encoder params:\", count_params(old_mcg))\n",
    "print(\"New ECG SMEE params:\", count_params(new_ecg))\n",
    "print(\"New MCG SMEE params:\", count_params(new_mcg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e9eedd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Total beats: 127\n",
      "Baseline ECG→MCG top-1:  7.09%\n",
      "Baseline MCG→ECG top-1:  7.87%\n",
      "Baseline ECG→MCG top-5: 29.13%\n",
      "Baseline MCG→ECG top-5: 29.13%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "#from koch_dataset import KochPairedBeatsDataset\n",
    "#from models import Conv1DEncoder, ProjectionHead\n",
    "\n",
    "\n",
    "def eval_koch_retrieval_baseline(\n",
    "    npz_path=\"koch_pairs.npz\",\n",
    "    ecg_encoder_path=\"ecg_encoder_koch.pth\",\n",
    "    mcg_encoder_path=\"mcg_encoder_koch.pth\",\n",
    "    ecg_proj_path=\"ecg_proj_koch.pth\",\n",
    "    mcg_proj_path=\"mcg_proj_koch.pth\",\n",
    "    batch_size=64,\n",
    "    device=\"cpu\",\n",
    "):\n",
    "    dataset = KochPairedBeatsDataset(npz_path=npz_path, augment=False)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "    # Baseline encoders\n",
    "    ecg_encoder = Conv1DEncoder(in_channels=32, feat_dim=256)\n",
    "    mcg_encoder = Conv1DEncoder(in_channels=100, feat_dim=256)\n",
    "\n",
    "    ecg_proj = ProjectionHead(in_dim=256, proj_dim=128)\n",
    "    mcg_proj = ProjectionHead(in_dim=256, proj_dim=128)\n",
    "\n",
    "    ecg_encoder.load_state_dict(torch.load(ecg_encoder_path, map_location=\"cpu\"))\n",
    "    mcg_encoder.load_state_dict(torch.load(mcg_encoder_path, map_location=\"cpu\"))\n",
    "    ecg_proj.load_state_dict(torch.load(ecg_proj_path, map_location=\"cpu\"))\n",
    "    mcg_proj.load_state_dict(torch.load(mcg_proj_path, map_location=\"cpu\"))\n",
    "\n",
    "    ecg_encoder.to(device).eval()\n",
    "    mcg_encoder.to(device).eval()\n",
    "    ecg_proj.to(device).eval()\n",
    "    mcg_proj.to(device).eval()\n",
    "\n",
    "    all_z_e, all_z_m = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for ecg, mcg in loader:\n",
    "            ecg = ecg.to(device)\n",
    "            mcg = mcg.to(device)\n",
    "\n",
    "            h_e = ecg_encoder(ecg)\n",
    "            h_m = mcg_encoder(mcg)\n",
    "\n",
    "            z_e = ecg_proj(h_e)\n",
    "            z_m = mcg_proj(h_m)\n",
    "\n",
    "            all_z_e.append(z_e.cpu())\n",
    "            all_z_m.append(z_m.cpu())\n",
    "\n",
    "    z_e = torch.cat(all_z_e, dim=0)\n",
    "    z_m = torch.cat(all_z_m, dim=0)\n",
    "    N = z_e.shape[0]\n",
    "    print(f\"Total beats: {N}\")\n",
    "\n",
    "    sim = z_e @ z_m.T  # (N, N)\n",
    "\n",
    "    # top-1\n",
    "    preds_e2m = sim.argmax(dim=1)\n",
    "    preds_m2e = sim.argmax(dim=0)\n",
    "    top1_e2m = (preds_e2m == torch.arange(N)).float().mean().item()\n",
    "    top1_m2e = (preds_m2e == torch.arange(N)).float().mean().item()\n",
    "\n",
    "    # top-5\n",
    "    K = 5\n",
    "    topk_e2m = sim.topk(K, dim=1).indices\n",
    "    topk_m2e = sim.topk(K, dim=0).indices\n",
    "\n",
    "    top5_e2m = (\n",
    "        (topk_e2m == torch.arange(N).unsqueeze(1)).any(dim=1).float().mean().item()\n",
    "    )\n",
    "    top5_m2e = (\n",
    "        (topk_m2e == torch.arange(N).unsqueeze(0)).any(dim=0).float().mean().item()\n",
    "    )\n",
    "\n",
    "    print(f\"Baseline ECG→MCG top-1:  {top1_e2m*100:.2f}%\")\n",
    "    print(f\"Baseline MCG→ECG top-1:  {top1_m2e*100:.2f}%\")\n",
    "    print(f\"Baseline ECG→MCG top-5: {top5_e2m*100:.2f}%\")\n",
    "    print(f\"Baseline MCG→ECG top-5: {top5_m2e*100:.2f}%\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(\"Using device:\", device)\n",
    "    eval_koch_retrieval_baseline(device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b836c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_on",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
