{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1b685a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BSPM] Loaded 33 channels, length 100000 samples\n",
      "[BSPM] Dropped channel 33 (respiration). New shape: (32, 100000)\n",
      "[MCG group] C:\\Users\\RAZER\\Documents\\GitHub\\Game_of_SQUIDE\\SQUIDE\\dATASET\\dataset_2\\koch\\MOESM7\\MCG_CH_A1 -> 17 channels, 100000 samples\n",
      "[MCG group] C:\\Users\\RAZER\\Documents\\GitHub\\Game_of_SQUIDE\\SQUIDE\\dATASET\\dataset_2\\koch\\MOESM7\\MCG_CH_V1 -> 19 channels, 100000 samples\n",
      "[MCG group] C:\\Users\\RAZER\\Documents\\GitHub\\Game_of_SQUIDE\\SQUIDE\\dATASET\\dataset_2\\koch\\MOESM7\\MCG_CH_X1 -> 15 channels, 100000 samples\n",
      "[MCG group] C:\\Users\\RAZER\\Documents\\GitHub\\Game_of_SQUIDE\\SQUIDE\\dATASET\\dataset_2\\koch\\MOESM8\\MCG_CH_Z1 -> 17 channels, 100000 samples\n",
      "[MCG group] C:\\Users\\RAZER\\Documents\\GitHub\\Game_of_SQUIDE\\SQUIDE\\dATASET\\dataset_2\\koch\\MOESM8\\MCG_CH_Z2 -> 16 channels, 100000 samples\n",
      "[MCG group] C:\\Users\\RAZER\\Documents\\GitHub\\Game_of_SQUIDE\\SQUIDE\\dATASET\\dataset_2\\koch\\MOESM8\\MCG_CH_Z3 -> 16 channels, 100000 samples\n",
      "[MCG] Total concatenated shape: (100, 100000)\n",
      "[ALIGN] ECG shape: (32, 100000), MCG shape: (100, 100000)\n",
      "[R-PEAKS] Detected 130 peaks\n",
      "[RESULT] ECG beats: (127, 32, 2000), MCG beats: (127, 100, 2000)\n",
      "[SAVE] Saved Koch ECG–MCG pairs to koch_pairs.npz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "from scipy.signal import butter, filtfilt, find_peaks\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# 1. PATHS – EDIT THIS PART\n",
    "# ==========================\n",
    "\n",
    "KOCH_ROOT = r\"C:\\Users\\RAZER\\Documents\\GitHub\\Game_of_SQUIDE\\SQUIDE\\dATASET\\dataset_2\\koch\"\n",
    "\n",
    "MOESM6_DIR = os.path.join(KOCH_ROOT, \"MOESM6\")  # BSPM (ECG-like)\n",
    "MOESM7_DIR = os.path.join(KOCH_ROOT, \"MOESM7\")  # part 1 of MCG (A1, V1, X1)\n",
    "MOESM8_DIR = os.path.join(KOCH_ROOT, \"MOESM8\")  # part 2 of MCG (Z1, Z2, Z3)\n",
    "\n",
    "OUT_FILE = \"koch_pairs.npz\"\n",
    "FS = 1000  # sampling frequency: 1 ms interval\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# 2. LOADING FUNCTIONS\n",
    "# ==========================\n",
    "\n",
    "def load_bspm_ecg(moesm6_dir):\n",
    "    \"\"\"\n",
    "    Load BSPM (ECG-like) signals from MOESM6/BSPM_data/BSPM_CH_E*.txt\n",
    "\n",
    "    Returns:\n",
    "        ecg_bspm: (C_ecg, T)\n",
    "        file_list: list of txt file paths\n",
    "    \"\"\"\n",
    "    bspm_folder = os.path.join(moesm6_dir, \"BSPM_data\")\n",
    "    txt_files = sorted(glob(os.path.join(bspm_folder, \"BSPM_CH_E*.txt\")))\n",
    "    if not txt_files:\n",
    "        raise RuntimeError(f\"No BSPM_CH_E*.txt files found in {bspm_folder}\")\n",
    "\n",
    "    channels = []\n",
    "    for f in txt_files:\n",
    "        data = np.loadtxt(f, dtype=np.float32)\n",
    "        channels.append(data)\n",
    "\n",
    "    # Align lengths\n",
    "    min_len = min(len(ch) for ch in channels)\n",
    "    channels = [ch[:min_len] for ch in channels]\n",
    "    ecg_bspm = np.stack(channels, axis=0)  # (C, T)\n",
    "\n",
    "    print(f\"[BSPM] Loaded {ecg_bspm.shape[0]} channels, length {ecg_bspm.shape[1]} samples\")\n",
    "\n",
    "    # Scale as per paper: multiply by -1.0 * 10^(-6) to get mV\n",
    "    ecg_bspm = -1.0e-6 * ecg_bspm\n",
    "\n",
    "    # Channel 33 is respiration → E33 → index 32 (0-based)\n",
    "    if ecg_bspm.shape[0] >= 33:\n",
    "        idx = np.arange(ecg_bspm.shape[0])\n",
    "        idx = idx[idx != 32]\n",
    "        ecg_bspm = ecg_bspm[idx, :]\n",
    "        print(f\"[BSPM] Dropped channel 33 (respiration). New shape: {ecg_bspm.shape}\")\n",
    "\n",
    "    return ecg_bspm, txt_files\n",
    "\n",
    "\n",
    "def load_mcg_group(folder):\n",
    "    \"\"\"\n",
    "    Load all *.txt files from a given MCG_CH_* folder, e.g. MCG_CH_A1, MCG_CH_Z1.\n",
    "\n",
    "    Returns:\n",
    "        arr: (C_group, T)\n",
    "        files: list of txt paths\n",
    "    \"\"\"\n",
    "    txt_files = sorted(glob(os.path.join(folder, \"MCG_CH_*.txt\")))\n",
    "    if not txt_files:\n",
    "        raise RuntimeError(f\"No MCG_CH_*.txt in {folder}\")\n",
    "\n",
    "    channels = []\n",
    "    for f in txt_files:\n",
    "        data = np.loadtxt(f, dtype=np.float32)\n",
    "        channels.append(data)\n",
    "\n",
    "    min_len = min(len(ch) for ch in channels)\n",
    "    channels = [ch[:min_len] for ch in channels]\n",
    "    arr = np.stack(channels, axis=0)\n",
    "    print(f\"[MCG group] {folder} -> {arr.shape[0]} channels, {arr.shape[1]} samples\")\n",
    "    return arr, txt_files\n",
    "\n",
    "\n",
    "def load_full_mcg(moesm7_dir, moesm8_dir):\n",
    "    \"\"\"\n",
    "    Load all MCG channels from MOESM7 (MCG_CH_A1, V1, X1) and\n",
    "    MOESM8 (MCG_CH_Z1, Z2, Z3) and concatenate along channel axis.\n",
    "\n",
    "    Returns:\n",
    "        mcg_full: (C_mcg_total, T)\n",
    "        file_list: list of paths\n",
    "    \"\"\"\n",
    "    # Known subfolders from your dir listing:\n",
    "    mcg_groups_7 = [\"MCG_CH_A1\", \"MCG_CH_V1\", \"MCG_CH_X1\"]\n",
    "    mcg_groups_8 = [\"MCG_CH_Z1\", \"MCG_CH_Z2\", \"MCG_CH_Z3\"]\n",
    "\n",
    "    all_arrays = []\n",
    "    all_files = []\n",
    "\n",
    "    # Load A1, V1, X1\n",
    "    for grp in mcg_groups_7:\n",
    "        folder = os.path.join(moesm7_dir, grp)\n",
    "        if os.path.isdir(folder):\n",
    "            arr, files = load_mcg_group(folder)\n",
    "            all_arrays.append(arr)\n",
    "            all_files.extend(files)\n",
    "        else:\n",
    "            print(f\"[WARN] Missing folder: {folder}\")\n",
    "\n",
    "    # Load Z1, Z2, Z3\n",
    "    for grp in mcg_groups_8:\n",
    "        folder = os.path.join(moesm8_dir, grp)\n",
    "        if os.path.isdir(folder):\n",
    "            arr, files = load_mcg_group(folder)\n",
    "            all_arrays.append(arr)\n",
    "            all_files.extend(files)\n",
    "        else:\n",
    "            print(f\"[WARN] Missing folder: {folder}\")\n",
    "\n",
    "    if not all_arrays:\n",
    "        raise RuntimeError(\"No MCG groups found in MOESM7 or MOESM8\")\n",
    "\n",
    "    # Align lengths across all groups\n",
    "    min_len = min(a.shape[1] for a in all_arrays)\n",
    "    all_arrays = [a[:, :min_len] for a in all_arrays]\n",
    "\n",
    "    mcg_full = np.concatenate(all_arrays, axis=0)  # (C_total, T)\n",
    "    print(f\"[MCG] Total concatenated shape: {mcg_full.shape}\")\n",
    "    return mcg_full, all_files\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# 3. R-PEAK DETECTION\n",
    "# ==========================\n",
    "\n",
    "def bandpass_filter(signal, fs=1000, low=5.0, high=15.0, order=2):\n",
    "    nyq = 0.5 * fs\n",
    "    b, a = butter(order, [low / nyq, high / nyq], btype=\"band\")\n",
    "    return filtfilt(b, a, signal)\n",
    "\n",
    "\n",
    "def detect_r_peaks(signal, fs=1000, distance_ms=300, height_factor=0.4):\n",
    "    \"\"\"\n",
    "    Very basic R-peak detector for clean signals.\n",
    "    \"\"\"\n",
    "    filtered = bandpass_filter(signal, fs=fs, low=5.0, high=15.0, order=2)\n",
    "    distance = int(distance_ms * fs / 1000.0)\n",
    "    height = height_factor * np.max(filtered)\n",
    "    peaks, _ = find_peaks(filtered, distance=distance, height=height)\n",
    "    return peaks\n",
    "\n",
    "\n",
    "def normalize_beat(x):\n",
    "    \"\"\"\n",
    "    Channel-wise median/MAD normalization for a single beat window.\n",
    "    x: (C, T)\n",
    "    \"\"\"\n",
    "    m = np.median(x, axis=1, keepdims=True)\n",
    "    mad = np.median(np.abs(x - m), axis=1, keepdims=True) + 1e-6\n",
    "    return (x - m) / mad\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# 4. MAIN\n",
    "# ==========================\n",
    "\n",
    "def main():\n",
    "    # Load ECG (BSPM)\n",
    "    ecg_bspm, ecg_files = load_bspm_ecg(MOESM6_DIR)\n",
    "\n",
    "    # Load MCG (all groups from MOESM7 + MOESM8)\n",
    "    mcg, mcg_files = load_full_mcg(MOESM7_DIR, MOESM8_DIR)\n",
    "\n",
    "    # Align time length between ECG and MCG\n",
    "    T = min(ecg_bspm.shape[1], mcg.shape[1])\n",
    "    ecg_bspm = ecg_bspm[:, :T]\n",
    "    mcg = mcg[:, :T]\n",
    "    print(f\"[ALIGN] ECG shape: {ecg_bspm.shape}, MCG shape: {mcg.shape}\")\n",
    "\n",
    "    # Choose one ECG channel for R-peaks (channel 0 for now)\n",
    "    r_lead = ecg_bspm[0, :]\n",
    "    r_peaks = detect_r_peaks(r_lead, fs=FS, distance_ms=300, height_factor=0.4)\n",
    "    print(f\"[R-PEAKS] Detected {len(r_peaks)} peaks\")\n",
    "\n",
    "    # Extract 2-second windows around each R-peak\n",
    "    pre = int(0.5 * FS)   # 500 ms before R\n",
    "    post = int(1.5 * FS)  # 1500 ms after R\n",
    "    win_len = pre + post  # 2000 samples\n",
    "\n",
    "    ecg_beats = []\n",
    "    mcg_beats = []\n",
    "\n",
    "    for r in r_peaks:\n",
    "        start = r - pre\n",
    "        end = r + post\n",
    "        if start < 0 or end > T:\n",
    "            continue\n",
    "\n",
    "        ecg_win = ecg_bspm[:, start:end]  # (C_ecg, win_len)\n",
    "        mcg_win = mcg[:, start:end]       # (C_mcg, win_len)\n",
    "\n",
    "        if ecg_win.shape[1] != win_len or mcg_win.shape[1] != win_len:\n",
    "            continue\n",
    "\n",
    "        ecg_norm = normalize_beat(ecg_win).astype(np.float32)\n",
    "        mcg_norm = normalize_beat(mcg_win).astype(np.float32)\n",
    "\n",
    "        ecg_beats.append(ecg_norm)\n",
    "        mcg_beats.append(mcg_norm)\n",
    "\n",
    "    ecg_beats = np.stack(ecg_beats, axis=0)  # (N, C_ecg, 2000)\n",
    "    mcg_beats = np.stack(mcg_beats, axis=0)  # (N, C_mcg, 2000)\n",
    "\n",
    "    print(f\"[RESULT] ECG beats: {ecg_beats.shape}, MCG beats: {mcg_beats.shape}\")\n",
    "\n",
    "    # Save to NPZ\n",
    "    np.savez_compressed(\n",
    "        OUT_FILE,\n",
    "        ecg_beats=ecg_beats,\n",
    "        mcg_beats=mcg_beats,\n",
    "        fs=np.array([FS], dtype=np.int32),\n",
    "        ecg_channel_files=np.array(ecg_files, dtype=object),\n",
    "        mcg_channel_files=np.array(mcg_files, dtype=object),\n",
    "        description=np.array([\"Koch ECG (BSPM) + SQUID MCG, paired 2s beats\"], dtype=object),\n",
    "    )\n",
    "    print(f\"[SAVE] Saved Koch ECG–MCG pairs to {OUT_FILE}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "137ce4ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECG beats: (127, 32, 2000)\n",
      "MCG beats: (127, 100, 2000)\n",
      "fs: [1000]\n",
      "desc: ['Koch ECG (BSPM) + SQUID MCG, paired 2s beats']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.load(\"koch_pairs.npz\", allow_pickle=True)\n",
    "ecg_beats = data[\"ecg_beats\"]\n",
    "mcg_beats = data[\"mcg_beats\"]\n",
    "\n",
    "print(\"ECG beats:\", ecg_beats.shape)  # (127, 32, 2000)\n",
    "print(\"MCG beats:\", mcg_beats.shape)  # (127, 100, 2000)\n",
    "print(\"fs:\", data[\"fs\"])\n",
    "print(\"desc:\", data[\"description\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "689c5a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class KochPairedBeatsDataset(Dataset):\n",
    "    def __init__(self, npz_path=\"koch_pairs.npz\", augment=False):\n",
    "        \"\"\"\n",
    "        npz_path: path to the koch_pairs.npz file\n",
    "        augment: if True, apply very light noise / jitter augmentations\n",
    "        \"\"\"\n",
    "        data = np.load(npz_path, allow_pickle=True)\n",
    "        self.ecg_beats = data[\"ecg_beats\"]  # (N, C_ecg, T)\n",
    "        self.mcg_beats = data[\"mcg_beats\"]  # (N, C_mcg, T)\n",
    "        self.fs = int(data[\"fs\"][0])\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.ecg_beats.shape[0]\n",
    "\n",
    "    def _augment(self, x):\n",
    "        \"\"\"\n",
    "        x: numpy array (C, T)\n",
    "        very light augmentations: small Gaussian noise and tiny time shift\n",
    "        \"\"\"\n",
    "        # small noise\n",
    "        x = x + 0.01 * np.random.randn(*x.shape).astype(np.float32)\n",
    "\n",
    "        # tiny circular time shift up to ±20 samples\n",
    "        max_shift = 20\n",
    "        shift = np.random.randint(-max_shift, max_shift + 1)\n",
    "        if shift != 0:\n",
    "            x = np.roll(x, shift, axis=1)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ecg = self.ecg_beats[idx]  # (C_ecg, T)\n",
    "        mcg = self.mcg_beats[idx]  # (C_mcg, T)\n",
    "\n",
    "        if self.augment:\n",
    "            ecg = self._augment(ecg)\n",
    "            mcg = self._augment(mcg)\n",
    "\n",
    "        # convert to torch tensors\n",
    "        ecg = torch.from_numpy(ecg)  # float32, shape (C_ecg, T)\n",
    "        mcg = torch.from_numpy(mcg)  # float32, shape (C_mcg, T)\n",
    "\n",
    "        return ecg, mcg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57168083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num beats: 127\n",
      "ECG batch shape: torch.Size([8, 32, 2000])\n",
      "MCG batch shape: torch.Size([8, 100, 2000])\n"
     ]
    }
   ],
   "source": [
    "#from koch_dataset import KochPairedBeatsDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "ds = KochPairedBeatsDataset(\"koch_pairs.npz\", augment=False)\n",
    "print(\"Num beats:\", len(ds))\n",
    "\n",
    "loader = DataLoader(ds, batch_size=8, shuffle=True)\n",
    "ecg, mcg = next(iter(loader))\n",
    "print(\"ECG batch shape:\", ecg.shape)  # expect: torch.Size([8, 32, 2000])\n",
    "print(\"MCG batch shape:\", mcg.shape)  # expect: torch.Size([8, 100, 2000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9b8eb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4466f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0cbc00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8870c32c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee26d5f0",
   "metadata": {},
   "source": [
    "# 1. PTB ECG – Prepare Beat-Level Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a879187d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import wfdb\n",
    "from scipy.signal import find_peaks, butter, filtfilt\n",
    "\n",
    "\n",
    "def list_ptb_records(ptb_root):\n",
    "    \"\"\"\n",
    "    ptb_root: path to PTB root folder, e.g. 'data/ptbdb'\n",
    "    Returns list of full record paths without extension, e.g. '.../patient001/s0010_re'\n",
    "    \"\"\"\n",
    "    rec_paths = []\n",
    "    for patient_dir in sorted(glob(os.path.join(ptb_root, 'patient*'))):\n",
    "        for rec in sorted(glob(os.path.join(patient_dir, '*.hea'))):\n",
    "            rec_paths.append(rec[:-4])  # strip '.hea'\n",
    "    return rec_paths\n",
    "\n",
    "\n",
    "def bandpass_filter(signal, fs=1000, low=5.0, high=15.0, order=2):\n",
    "    \"\"\"\n",
    "    Simple bandpass filter for QRS detection.\n",
    "    signal: 1D numpy array\n",
    "    fs: sampling frequency\n",
    "    \"\"\"\n",
    "    nyq = 0.5 * fs\n",
    "    b, a = butter(order, [low / nyq, high / nyq], btype='band')\n",
    "    return filtfilt(b, a, signal)\n",
    "    \n",
    "\n",
    "def detect_r_peaks(ecg_lead, fs=1000, distance_ms=300, height_factor=0.5):\n",
    "    \"\"\"\n",
    "    Very basic R-peak detector on a single lead.\n",
    "    ecg_lead: 1D numpy array\n",
    "    distance_ms: minimum distance between peaks\n",
    "    height_factor: relative threshold on peak height\n",
    "    Returns indices of R-peaks.\n",
    "    \"\"\"\n",
    "    filtered = bandpass_filter(ecg_lead, fs=fs, low=5.0, high=15.0)\n",
    "    distance = int(distance_ms * fs / 1000.0)\n",
    "    # rough threshold: height_factor * max\n",
    "    height = height_factor * np.max(filtered)\n",
    "    peaks, _ = find_peaks(filtered, distance=distance, height=height)\n",
    "    return peaks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adc47b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import wfdb\n",
    "from collections import defaultdict\n",
    "\n",
    "PTB_ROOT = \"data/ptbdb\"    # TODO: change to your path\n",
    "OUT_FILE = \"ptb_beats.npz\" # output\n",
    "\n",
    "# standard 12 leads in PTB header\n",
    "STANDARD_LEADS = ['i', 'ii', 'iii', 'avr', 'avl', 'avf',\n",
    "                  'v1', 'v2', 'v3', 'v4', 'v5', 'v6']\n",
    "\n",
    "all_beats = []\n",
    "all_record_names = []\n",
    "all_subject_ids = []\n",
    "all_labels = []  # you can later fill with MI/non-MI, etc.\n",
    "\n",
    "rec_paths = list_ptb_records(PTB_ROOT)\n",
    "print(f\"Found {len(rec_paths)} records\")\n",
    "\n",
    "for rec_path in rec_paths:\n",
    "    try:\n",
    "        record = wfdb.rdrecord(rec_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to read {rec_path}: {e}\")\n",
    "        continue\n",
    "\n",
    "    sig = record.p_signal  # shape (T, n_channels)\n",
    "    fs = int(record.fs)    # should be 1000\n",
    "    ch_names = [ch.lower() for ch in record.sig_name]\n",
    "\n",
    "    # map lead names to indices\n",
    "    lead_indices = []\n",
    "    for ln in STANDARD_LEADS:\n",
    "        if ln in ch_names:\n",
    "            lead_indices.append(ch_names.index(ln))\n",
    "        else:\n",
    "            print(f\"Lead {ln} not found in {rec_path}, skipping record.\")\n",
    "            lead_indices = []\n",
    "            break\n",
    "\n",
    "    if not lead_indices:\n",
    "        continue\n",
    "\n",
    "    ecg_12 = sig[:, lead_indices].T  # shape (12, T)\n",
    "    T = ecg_12.shape[1]\n",
    "\n",
    "    # use lead II for R-peak detection\n",
    "    lead2_index = ch_names.index('ii')\n",
    "    lead2 = sig[:, lead2_index]\n",
    "    r_peaks = detect_r_peaks(lead2, fs=fs, distance_ms=300, height_factor=0.4)\n",
    "\n",
    "    if len(r_peaks) < 5:\n",
    "        print(f\"Few R-peaks in {rec_path}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    # 2-second window: [-500ms, +1500ms] → 2000 samples\n",
    "    pre = int(0.5 * fs)\n",
    "    post = int(1.5 * fs)\n",
    "    win_len = pre + post\n",
    "\n",
    "    for r in r_peaks:\n",
    "        start = r - pre\n",
    "        end = r + post\n",
    "        if start < 0 or end > T:\n",
    "            continue\n",
    "        beat = ecg_12[:, start:end]  # (12, 2000)\n",
    "        if beat.shape[1] != win_len:\n",
    "            continue\n",
    "\n",
    "        # simple per-beat normalization (median + MAD)\n",
    "        m = np.median(beat, axis=1, keepdims=True)\n",
    "        mad = np.median(np.abs(beat - m), axis=1, keepdims=True) + 1e-6\n",
    "        beat_norm = (beat - m) / mad\n",
    "\n",
    "        all_beats.append(beat_norm.astype(np.float32))\n",
    "        all_record_names.append(os.path.basename(rec_path))\n",
    "        # subject id is patient folder name\n",
    "        all_subject_ids.append(os.path.basename(os.path.dirname(rec_path)))\n",
    "        all_labels.append(0)  # placeholder; you can parse .hea for diagnosis later\n",
    "\n",
    "all_beats = np.stack(all_beats, axis=0)  # (N, 12, 2000)\n",
    "all_record_names = np.array(all_record_names)\n",
    "all_subject_ids = np.array(all_subject_ids)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "print(\"PTB beats shape:\", all_beats.shape)\n",
    "\n",
    "np.savez_compressed(\n",
    "    OUT_FILE,\n",
    "    beats=all_beats,\n",
    "    record_names=all_record_names,\n",
    "    subject_ids=all_subject_ids,\n",
    "    labels=all_labels,\n",
    "    fs=np.array([1000], dtype=np.int32),\n",
    "    description=np.array([\"PTB 12-lead beats, 2s windows around R-peaks\"], dtype=object)\n",
    ")\n",
    "print(f\"Saved PTB beats to {OUT_FILE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f026130",
   "metadata": {},
   "source": [
    "# 2. Koch ECG–MCG – Prepare Paired Beat Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f49cbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
